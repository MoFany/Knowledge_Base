# Redis常用语法

##### :panda_face:Author：MoFany-J

## Reids简介`6379`

>#### reidis概述
>
>* **Remote DIctionary Server(Redis) 是一个由 Salvatore Sanfilippo 写的 `key-value`存储系统，是`跨平台的非关系型数据库`。**
>
>* **Redis 是一个开源的`使用 ANSI C 语言编写`、遵守 BSD 协议、支持网络、可基于内存、分布式、`可选持久性的键值对(Key-Value)存储数据库`，并提供多种语言的 API。**
>
>* **Redis 通常被称为数据结构服务器，因为`值（value）可以是字符串(String)、哈希(Hash)、列表(list)、集合(sets)和有序集合(sorted sets)等类型`。**
>
>#### Redis核心
>
>* NoSQL的数据存储方式为内存，NoSQL事务特性遵循BASE理论
>
>* Redis没有表操作概念，即其存在库中，可通过json串构造类似表的数据，每次只往同一个json中存数据
>
>* Redis默认有16个数据库，其可以执行CRUD操作，且数据库里面的数据都是以键值对的形式存储的
>
>* Redis数据库数据No SQL，而No SQL要么无法满足或全部满足ACID特性，该情况称为Base理论
>
>#### Redis的特点
>
>1. 键值型`key-value`，key一般是一个字符串而value支持多种不同数据结构，功能丰富
>2. 单线程，每个命令具备原子性，`redis6.0仅对网络请求处理方面进行了多线程设计，而核心命令执行依然是单线程`
>3. 低延迟，速度快（**基于内存**、IO多路复用、良好的编码）
>4. 支持数据持久化
>5. 支持主从集群、分片集群
>6. 支持多语言客户端 

## Redis的数据库

> ##### Redis中数据库默认有十六个，下标默认从0开始到15为止
>
> ```properties
> # Set the number of databases. The default database is DB 0, you can select
> # a different one on a per-connection basis using SELECT <dbid> where
> # dbid is a number between 0 and 'databases'-1
> databases 16
> ```

## Redis任意类型通用命令

> #### 特殊操作
>
> - ###### `ping`连通性测试
>
> - ###### 命令查询手册：`help @数据类型`
>
> - ###### `select index`选择指定索引的库，索引范围`0 ~ 15`
>
> #### 通用数据操作
>
> - ###### `keys 通配符表达式`查看符合模版的所有key
>
>   - 通配符`*`，表示多个字符
>   - 通配符`?`，表示一个字符
>
> - ###### `mset [key1 value1] [key2 value2] ...`批量插入多个键值对
>
> - ###### `del [key1 key2 ...]`删除一个或多个key对应的键值
>
> - ###### `exists [key1 key2 ...]`判断指定的一个或多个key是否存在
>
> - ###### `expire key seconds`给一个key设置有效期（单位秒），有效期到时key自动被删除
>
> - ###### `ttl key`查看一个key的剩余有效期

## 基本数据类型操作

>### Redis中key的推荐格式：`[项目名]:[业务]:[Tname]:[key]`
>
>#### `String`set/get
>
>###### Redis中最简单的数据类型
>
>```properties
>+ - - - - - - - - - - - + - - - - - - - - - - - - - - - +
>|        KEY            |            VALUE              |
>+ - - - - - - - - - - - + - - - - - - - - - - - - - - - +
>|                       |                               |
>|                       |    {                          |
>|                       |       "name": "mofany",       |
>| com:mofany:student:1  |       "sex": "male"           |
>|                       |     }                         |
>|                       |                               |
>+ - - - - - - - - - - - + - - - - - - - - - - - - - - - +
>```
>
>```sql
>127.0.0.1:6379> set com:mofany:student:1 '{"name":"mofany","sex":"male"}'
>OK
>127.0.0.1:6379> keys *
>1) "com:mofany:student:1"
>```
>
>* **`set key value ex seconds`**添加或修改（已存在基础上修改）已经存在的一个String类型的键值对，指定有效期
>* **`get key`**根据key获取String类型的value
>* **`mset [key1 value1] [key2 value2] ...`**批量添加多个String类型的value
>* **`mget [key1 key2 ...]`**批量返回多个Key的值
>* **`incr intKey`**让一个整型的key自增1
>* **`incrby intKey step`**让一个整型的key自增并指定步长
>* **`decr key`**整型key自减，相当于`incrby intKey -1`
>* **`incrbyfloat floatKey 0.5`**让一个浮点类型的数字自增并指定任意步长，
>* **`setnx newKey newValue`**添加一个String类型的键值对，前提是该key不存在，否则不执行
>* **`setex newKey seconds newValue`**添加一个Stirng类型的键值对，并且指定有效期
>
>#### `List`lpush/lpop
>
>- 有序
>- 元素可以重复
>- 插入删除效率高`插入删除不会移动大量元素，其只是改变了双向链表相应节点指针域的指向`
>- 查询效率不高`查询效率比传统数组低，因为数组支持索引的随机访问`
>
>###### 其数据结构是一个双向链表结构，故即支持正向所有也支持反向索引
>
>```properties
>---- left PUSH ---->       + - - - - - - +           + - - - - - - +        <---- right PUSH ----   
>                           |     A       | <-------> |     B       |        
><--- left POP  -----       + - - - - - - +           + - - - - - - +        ----- right POP  --->
>
>       角标：                     0                         1
>```
>
>* **`lpush key 元素 ...`**向列表左侧插入一个或多个元素，**链表左端依次入队**
>
>  ```sql
>  -- 1 2 3 链表左端依次入队
>  127.0.0.1:6379> lpush users 1 2 3
>  (integer) 3
>  
>  /* 存入后结果
>  + - - - - - +
>  |     3     |  0
>  + - - - - - +
>  |     2     |  1
>  + - - - - - +
>  |     1     |  3
>  + - - - - - +
>  */
>  
>  -- 查看指定角标范围的元素
>  127.0.0.1:6379> lrange users 0 2
>  1) "3"
>  2) "2"
>  3) "1"
>  ```
>
>* **`lpop key 元素个数`**移除并返回列表左侧的第一个元素，没有则返回nil，**链表左端依次出队**
>
>* **`rpush key 元素 ...`**向列表右侧插入一个或多个元素，**链表右端依次入队**
>
>  ```sql
>  -- 4 5 6 链表右端依次入队
>  127.0.0.1:6379> rpush users 4 5 6
>  
>  /* 存入后的结果
>  + - - - - - +
>  |     3     |  0
>  + - - - - - +
>  |     2     |  1
>  + - - - - - +
>  |     1     |  2
>  + - - - - - +
>        +
>  + - - - - - +
>  |     4     |  3
>  + - - - - - +
>  |     5     |  4
>  + - - - - - +
>  |     6     |  5
>  + - - - - - +
>  */
>  
>  -- 查看指定角标范围的元素
>  (integer) 6
>  127.0.0.1:6379> lrange users 3 5
>  1) "4"
>  2) "5"
>  3) "6"
>  ```
>
>* **`rpop key 元素个数`**移除并返回列表右侧的第一个元素，**链表右端依次出队**
>
>* **`lrange key star end`**返回一段角标范围内（star~end，包含这两个边界）的所有元素
>
>  * ##### `range`使用的是角标，角标默认从0开始
>
>* **`blpop key1 ... timeout`**阻塞式`lpop`，不同之处在于没有元素时等待指定时间**（在等待过程中一旦出现该元素则结束等待并返回指定元素）**，而不是直接返回nil
>
>* **`brpop key1 ... timeout`**阻塞式`rpop`，不同之处在于没有元素时等待指定时间**（在等待过程中一旦出现该元素则结束等待并返回指定元素）**，而不是直接返回nil
>
>  ```sql
>  -- 用户A：出队user2不存在，用户A的操作阻塞100秒
>  127.0.0.1:6379> blpop user2 100
>  
>  -- 管理员：入队user2
>  127.0.0.1:6379> lpush user2 1 2 3
>  (integer) 3
>  
>  -- 用户A：停止阻塞，返回元素
>  127.0.0.1:6379> blpop user2 100
>  1) "user2"
>  2) "3"
>  (62.42s) -- 共阻塞62.42秒
>  ```
>
>#### `Set`sadd/srem
>
>###### 其类似于HashSet，可以看作是一个value为null的HashMap，由于是一个hash表，故具有HashSet的特点：
>
>* ###### 无序
>
>* ###### 唯一
>
>* ###### 查找快
>
>* ###### 支持交集、并集、差集操作
>
>  * 交集`共同好友`
>  * 并集`所有好友`
>  * 差集`推荐好友`**差集中集合的的前后顺序很重要**
>
>* **`sadd key member [member] ... `**一次性向集合中添加一个或多个元素
>
>  ```sql
>  127.0.0.1:6379> sadd s1 a b c
>  (integer) 3
>  ```
>
>* **`scard key`**返回集合中元素的个数
>
>  ```sql
>  127.0.0.1:6379> scard s1
>  (integer) 3
>  ```
>
>* **`sismember key member`**判断一个元素是否存在于集合中
>
>  ```sql
>  127.0.0.1:6379> sismember s1 a
>  (integer) 1
>  127.0.0.1:6379> sismember s1 d
>  (integer) 0
>  ```
>
>* **`smembers key`**获取集合中所有元素
>
>  ```sql
>  127.0.0.1:6379> smembers s1
>  1) "b"
>  2) "a"
>  3) "c"
>  ```
>
>* **`srem key members ...`**移除集合中的指定元素
>
>  ```sql
>  -- 移除集合s1中的a、b元素
>  127.0.0.1:6379> srem s1 a b c
>  (integer) 3
>  -- 查看剩余元素
>  127.0.0.1:6379> smembers s1
>  (empty array)
>  ```
>
>* **`sinter key1 key2 ...`**求key1集合与key2集合的交集
>
>  ```sql
>  127.0.0.1:6379> sadd s1 a b c
>  (integer) 3
>  127.0.0.1:6379> sadd s2 b c d
>  (integer) 3
>  
>  -- 求s1集合与s2集合的交集
>  127.0.0.1:6379> sinter s1 s2
>  1) "b"
>  2) "c"
>  ```
>
>* **`sdiff key1 key2 ...`**求key1集合与key2集合的差集，**差集中集合的的前后顺序很重要，在前者前减后**
>
>  ```sql
>  127.0.0.1:6379> sadd s1 a b c
>  (integer) 3
>  127.0.0.1:6379> sadd s2 b c d
>  (integer) 3
>  
>  -- 求s1集合与s2集合的差集
>  127.0.0.1:6379> sdiff s1 s2
>  1) "a"
>  ```
>
>* **`sunion key1 key2 ...`**求key1集合与key2集合的并集**默认会去重复**
>
>  ```sql
>  127.0.0.1:6379> sadd s1 a b c
>  (integer) 3
>  127.0.0.1:6379> sadd s2 b c d
>  (integer) 3
>  
>  -- 求s1集合与s2集合的并集
>  127.0.0.1:6379> sunion s1 s2
>  1) "b"
>  2) "a"
>  3) "c"
>  4) "d"
>  ```
>
>#### `Sorted Set`zadd/zrem`默认升序`
>
>###### 其是一个可排序的集合，与java中的TreeSet功能相似，但底层数据结构不同。SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表`SikpList`加hash表
>
>* ###### 可排序`SortedSet常用于实现排行榜功能`
>
>* ###### 唯一性
>
>* ###### 查询速度快
>
>* ***所有的排名都默认升序，若要降序则在命令的`z`后面添加`rev`即可***
>
>* **`zadd key score member [score member] ...`**添加一个或多个元素到sorted set，如果已经存在则更新其score值
>
>  ```sql
>  127.0.0.1:6379> zadd stus 85 Jack 89 Lucy 82 Rose 95 Tom 78 Jerry 92 Amy 76 Miles
>  (integer) 7
>  ```
>
>* **`zrem key member [member]...`**删除sorted set中的指定元素
>
>* **`zcard key`**获取sorted set中元素的个数
>
>* **`zscore key member`**获取sorted set中的指定元素的score值
>
>  ```sql
>  127.0.0.1:6379> zscore stus Miles
>  "76"
>  ```
>
>* **`zrank key member`**获取sorted set中的指定元素的排名
>
>  ```sql
>  127.0.0.1:6379> zrank stus Miles
>  (integer) 0
>  ```
>
>* ##### **`zcount key scoreMin scoreMax`**统计score值在给定范围内的所有元素个数
>
>  ```sql
>  -- 成绩在80分以下（包含边界）的人数
>  127.0.0.1:6379> zcount stus 0 80
>  (integer) 2
>  ```
>
>* ##### **`zrange key min max`**按照score排序后，获取指定排名范围内的元素`按名次升序、降序显示排行`
>
>  * ##### `range`使用的是角标，角标默认从0开始
>
>  ```sql
>  -- 降序，前三名
>  127.0.0.1:6379> zrevrange stus 0 2
>  1) "Tom"
>  2) "Amy"
>  3) "Lucy"
>  
>  -- 升序，后三名
>  127.0.0.1:6379> zrange stus 0 2
>  1) "Miles"
>  2) "Jerry"
>  3) "Rose"
>  ```
>
>* ##### **`zrangebyscore key scoreMin scoreMax`**按照score排序后，获取指定score范围内的元素`排名后按成绩筛选`
>
>  ```sql
>  -- 80分以下的按升序输出
>  127.0.0.1:6379> zrangebyscore stus 0 79
>  1) "Miles"
>  2) "Jerry"
>  ```
>
>* ##### **`zincrby key increment member`**让sorted set中的指定元素自增，步长为increment值`increment为增量`
>
>  ```sql
>  -- Tom加2分
>  127.0.0.1:6379> zincrby stus 2 Tom
>  "97"
>  ```
>
>* ##### **`zdiff、zinter、zunion`**求交集、差集、并集
>
>#### `Hash`hset/hget
>
>###### 其值是一个无序字典，类似与java中HashMap结构，Hash结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD
>
>```properties
>+ - - - - - - - - - - - + - - - - - - - - - - - - - - - +
>|                       |            VALUE              |
>+         KEY           + - - - - - - - + - - - - - - - +
>|                       |     field     |      value    |
>+ - - - - - - - - - - - + - - - - - - - + - - - - - - - +
>|                       |      name     |      Jack     |
>|    mofany:uer:1       + - - - - - - - + - - - - - - - +
>|                       |      age      |      23       |
>+ - - - - - - - - - - - + - - - - - - - + - - - - - - - +
>```
>
>```sql
>-- 添加一条新数据
>127.0.0.1:6379> hset mofany:user:1 name Jack age 23
>(integer) 2
>-- 查看所有键
>127.0.0.1:6379> keys *
>1) "mofany:user:1"
>-- 修改前查看数据
>127.0.0.1:6379> hget mofany:user:1 name
>"Jack"
>127.0.0.1:6379> hget mofany:user:1 age
>"23"
>
>-- 修改数据
>127.0.0.1:6379> hset mofany:user:1 age 19
>(integer) 0
>-- 修改后查看数据
>127.0.0.1:6379> hget mofany:user:1 name
>"Jack"
>127.0.0.1:6379> hget mofany:user:1 age
>"19"
>```
>
>* **`hset 键 field字段 值`**添加或修改hash类型key的field的值
>
>* **`hget 键 field字段`**获取一个hash类型key的field的值
>
>* **`hmset 键 [field1 value1] [field2 value2] ...`**批量添加单个hash类型key，对应的多个field值
>
>* **`hmget 键 [field1 field2 ...]`**批量获取单个hash类型key，对应的多个field值
>
>* **`hgetall`**获取一个hash类型的key中的所有的field和value
>
>  ```sql
>  -- 获取当前key所对应的所有的field字段及其对应值
>  127.0.0.1:6379> hgetall mofany:user:1
>  1) "name"
>  2) "Jack"
>  3) "age"
>  4) "19"
>  ```
>
>* **`hkeys`**获取一个hash类型的key中的所有field
>
>  ```sql
>  -- 获取当前key对应的所有的field字段
>  127.0.0.1:6379> hkeys mofany:user:1
>  1) "name"
>  2) "age"
>  ```
>
>* **`hvals`**获取一个hash类型的key中的所有value
>
>  ```sql
>  -- 获取当前key的所有的field字段所对应的value值
>  127.0.0.1:6379> hvals mofany:user:1
>  1) "Jack"
>  2) "19"
>  ```
>
>* **`hincrby 键 intField [step正自增，负自减]`**让一个hash类型key的字段值自增并指定步长
>
>* **`hsetnx 键 newField 值`**添加一个hash类型的key的field值，前提是这个field必须不存在，否则不执行

## :boxing_glove:如何用List模拟一个栈？

>### `入出一致`
>
>#### `rpush + rpop`
>
>```sql
>-- 链表右端，依次入队
>127.0.0.1:6379> rpush user2 1 2 3 4
>(integer) 4
>-- 入队后正常顺序
>127.0.0.1:6379> lrange user2 0 3
>1) "1"
>2) "2"
>3) "3"
>4) "4"
>
>-- 链表右端，依次出队
>127.0.0.1:6379> rpop user2 4
>1) "4"
>2) "3"
>3) "2"
>4) "1"
>```
>
>#### `lpush + lpop`
>
>```sql
>-- 链表左端，依次入队
>127.0.0.1:6379> lpush user2 1 2 3 4
>(integer) 4
>
>-- 链表左端，依次出队
>127.0.0.1:6379> lpop user2 4
>1) "4"
>2) "3"
>3) "2"
>4) "1"
>```

## :boxing_glove:如何用List模拟一个队列？

>### `入出互斥`
>
>#### `lush + rpop`
>
>```sql
>-- 链表左端，依次入队
>127.0.0.1:6379> lpush user2 1 2 3 4
>(integer) 4
>-- 入队后正常顺序
>127.0.0.1:6379> lrange user2 0 3
>1) "4"
>2) "3"
>3) "2"
>4) "1"
>
>-- 链表右端，依次出队
>127.0.0.1:6379> rpop user2 4
>1) "1"
>2) "2"
>3) "3"
>4) "4"
>```
>
>#### `rpush + lpop`
>
>```sql
>-- 链表右端，依次入队
>127.0.0.1:6379> rpush user2 1 2 3 4
>(integer) 4
>
>-- 链表左端，依次出队
>127.0.0.1:6379> lpop user2 4
>1) "1"
>2) "2"
>3) "3"
>4) "4"
>```

## :boxing_glove:如何利用List结构模拟一个阻塞队列？

>### 保证是一个队列：`入出互斥，且采用blpop或brpop`
>
>#### `lpush + brpop`
>
>```sql
>-- 链表左端，依次入队
>127.0.0.1:6379> lpush user2 1 2 3 4
>(integer) 4
>-- 入队后正常顺序
>127.0.0.1:6379> lrange user2 0 3
>1) "4"
>2) "3"
>3) "2"
>4) "1"
>
>-- 阻塞出队，有则取无则不取
>127.0.0.1:6379> brpop user2 4
>1) "user2"
>2) "1"
>127.0.0.1:6379> brpop user2 4
>1) "user2"
>2) "2"
>127.0.0.1:6379> brpop user2 4
>1) "user2"
>2) "3"
>127.0.0.1:6379> brpop user2 4
>1) "user2"
>2) "4"
>127.0.0.1:6379> brpop user2 4
>(nil)
>(4.02s) -- 无元素了阻塞4秒
>```
>
>#### `rpush + blpop`
>
>```sql
>-- 链表右端，依次入队
>127.0.0.1:6379> rpush user2 1 2 3 4
>(integer) 4
>-- 入队后正常顺序
>127.0.0.1:6379> lrange user2 0 3
>1) "1"
>2) "2"
>3) "3"
>4) "4"
>
>-- 阻塞出队，有则取无则不取
>127.0.0.1:6379> blpop user2 4
>1) "user2"
>2) "1"
>127.0.0.1:6379> blpop user2 4
>1) "user2"
>2) "2"
>127.0.0.1:6379> blpop user2 4
>1) "user2"
>2) "3"
>127.0.0.1:6379> blpop user2 4
>1) "user2"
>2) "4" -- 无元素了阻塞4秒
>```

## :boxing_glove:如何利用set集合实现好友的各个功能？

>#### 构建数据模型
>
>* 张三的好友有：李四、王五、赵六
>
>* 李四的好友有：王五、麻子、二狗
>
>```sql
>-- 构建数据
>127.0.0.1:6379> sadd zs_set 李四 王五 赵六
>3
>127.0.0.1:6379> sadd ls_set 王五 麻子 二狗
>3
>127.0.0.1:6379>
>
>-- 查看数据
>127.0.0.1:6379> smembers zs_set
>李四
>王五
>赵六
>127.0.0.1:6379> smembers ls_set
>麻子
>二狗
>王五
>```
>
>#### 操作
>
>1. 计算张三的好友人数
>
>   ```sql
>   127.0.0.1:6379> scard zs_set
>   3
>   ```
>
>2. 计算张三与李四有哪些共同好友`交集`
>
>   ```sql
>   127.0.0.1:6379> sinter zs_set ls_set
>   王五
>   ```
>
>3. 查询哪些人是张三的好友却不是李四的好友`差集`
>
>   ```sql
>   -- 差集中顺序很重要 zs_set - ls_set，在前者前减后
>   127.0.0.1:6379> sdiff zs_set ls_set
>   李四
>   赵六
>   ```
>
>4. 查询张三和李四的好友总共有哪些人`并集`
>
>   ```sql
>   127.0.0.1:6379> sunion zs_set ls_set
>   麻子
>   王五
>   赵六
>   二狗
>   李四
>   ```
>
>5. 判断李四是不是张三的好友，是则将李四从张三好友列表删除
>
>   ```sql
>   127.0.0.1:6379> sismember zs_set 李四
>   1
>   127.0.0.1:6379> srem zs_set 李四
>   1
>   ```
>
>6. 判断张三是不是李四的好友
>
>   ```sql
>   127.0.0.1:6379> sismember ls_set 张三
>   0
>   ```

## 特殊数据类型操作

>* `Stream`
>
>* `Stream tutorial`
>
>* `Geospatial`地理坐标
>
>* `HyperLogLog`按位存储
>
>* `Bitmap`按位存储
>
>* `Btifield`

# Redis结合Java

## Jedis

>#### 依赖
>
>```xml
><dependency>
>    <groupId>redis.clients</groupId>
>    <artifactId>jedis</artifactId>
>    <version>4.0.0</version>
></dependency>
>```
>
>#### 测试Demo
>
>* ##### jedis所有操作都是基于reids命令进行的
>
>```java
>package com.mofany.test;
>
>import org.junit.After;
>import org.junit.Before;
>import org.junit.Test;
>import redis.clients.jedis.Jedis;
>
>import java.util.Iterator;
>import java.util.Map;
>import java.util.Set;
>
>/**
> * @author MoFany-J
> * @date 2023/3/5
> * @description JedisTest
> */
>public class JedisTest {
>
>    /**
>     * redis所在远程主机的ip
>     */
>    private String hostIP = "192.168.85.150";
>
>    /**
>     * 创建jedis实例
>     */
>    private Jedis jedis;
>
>    /**
>     * 创建连接
>     */
>    @Before
>    public void setJedis() {
>        // 1.建立连接（直连）
>        jedis = new Jedis(hostIP, 6379);
>        
>        // 1.从连接池中获取连接
>        //jedis = JedisConnectionPool.getJedis();
>        
>        // 2.设置密码（没有设置密码直接为空串）
>        jedis.auth("default", "");
>        // 3.选择库
>        jedis.select(0);
>    }
>
>    /**
>     * 释放连接
>     */
>    @After
>    public void tear() {
>        if (jedis != null) {
>            jedis.close();
>        }
>    }
>
>    /**
>     * String类型存key-value
>     */
>    @Test
>    public void set() {
>        // 存入数据
>        String result = jedis.set("name", "默凡语");
>        System.out.println(result);
>    }
>
>    /**
>     * String类型获取key-value
>     */
>    @Test
>    public void get() {
>        // 取数据
>        String name = jedis.get("name");
>        System.out.println(name);
>    }
>
>    /**
>     * String类型修改key-value
>     */
>    @Test
>    public void update() {
>        // 修改key的value
>        String result = jedis.set("name", "路飞太郎");
>        System.out.println(result);
>    }
>
>    /**
>     * String类型删除key-value
>     */
>    @Test
>    public void delete() {
>        // 删除指定key
>        long result = jedis.del("name");
>        System.out.println(result);
>    }
>
>    /**
>     * Hash类型存key-value
>     */
>    @Test
>    public void hSet() {
>        // 存
>        long result = jedis.hset("student:1", "name", "娜娜米");
>        System.out.println(result);
>        result = jedis.hset("student:1", "age", "23");
>        System.out.println(result);
>    }
>
>    /**
>     * Hash类型取key-value
>     */
>    @Test
>    public void hGet() {
>        // 获取
>        Map<String, String> resultMap = jedis.hgetAll("student:1");
>        // 遍历map
>        Set<Map.Entry<String, String>> entries = resultMap.entrySet();
>        Iterator<Map.Entry<String, String>> iterator = entries.iterator();
>        while (iterator.hasNext()) {
>            System.out.println(iterator.next());
>        }
>    }
>
>    /**
>     * Hash类型改key-value
>     */
>    @Test
>    public void hUpdate() {
>        // 修改
>        long result = jedis.hset("student:1", "name", "娜美");
>        System.out.println(result);
>        result = jedis.hset("student:1", "age", "19");
>        System.out.println(result);
>    }
>
>    /**
>     * Hash类型删key-value
>     */
>    @Test
>    public void hDel() {
>        // 删除
>        System.out.println(jedis.hdel("student:1", "name"));
>        System.out.println(jedis.hdel("student:1", "age"));
>    }
>}
>```
>
>#### jedis连接池
>
>* ##### jedis本身是线程不安全的，并且频繁创建与销毁连接会有性能损耗，因此建议使用jedis连接池替代jedis直接连接方式
>
>```java
>package com.mofany.util;
>
>import redis.clients.jedis.Jedis;
>import redis.clients.jedis.JedisPool;
>import redis.clients.jedis.JedisPoolConfig;
>
>/**
> * @author MoFany-J
> * @date 2023/3/5
> * @description JedisConnectionPool Jedis连接池，池技术都是利用了享元设计模式
> */
>public class JedisConnectionPool {
>
>    /**
>     * 远程redis所在主机的ip
>     */
>    private static String hostIP = "192.168.85.150";
>
>    /**
>     * 连接池对象
>     */
>    private static final JedisPool jedisPool;
>
>    static {
>        // jedis连接池配置
>        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
>        // 最大连接
>        jedisPoolConfig.setMaxTotal(8);
>        // 最大空闲连接
>        jedisPoolConfig.setMaxIdle(8);
>        // 最小空闲连接
>        jedisPoolConfig.setMinIdle(0);
>        // 设置最长等待时间，ms
>        jedisPoolConfig.setMaxWaitMillis(200);
>        // 类加载时创建连接池对象
>        jedisPool = new JedisPool(jedisPoolConfig, hostIP, 6379, 1000, "default", "");
>    }
>
>    private JedisConnectionPool() {
>        if (jedisPool != null) {
>            throw new RuntimeException("禁止反射!");
>        }
>    }
>
>    /**
>     * 单例饿汉式，获取Jedis对象
>     */
>    public static Jedis getJedis() {
>        return jedisPool.getResource();
>    }
>}
>```
>

## Spring Data Redis

>#### SpringData是Spring数据操作模块，包含对各种数据库的集成，其对Redis的集成模块就叫做Spring Data Redis
>
>* 提供了对不同Redis客户端的整合（Lettuce和Jedis）
>* 提供了RedisTemplate统一API来操作Reids
>* 支持Reids的发布订阅模型
>* 支持Redis哨兵和Redis集群
>* 支持基于Lettuce的响应式编程
>* 支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化
>* 支持基于Redis的JDKCollection实现
>
>#### RedisTemplate工具类，封装类各种对Redis的操作且不同数据类型的操作API封装到了不同的类型中
>
>| API                           | 返回值类型      | 描述                    |
>| ----------------------------- | --------------- | ----------------------- |
>| redisTemplate.`opsForValue()` | ValueOperations | 操作`String`类型数据    |
>| redisTemplate.`opsForHash()`  | HashOperations  | 操作`Hash`类型数据      |
>| redisTemplate.`opsForList()`  | ListOperations  | 操作`List`类型数据      |
>| redisTemplate.`opsForSet()`   | SetOperations   | 操作`Set`类型数据       |
>| redisTemplate.`opsForZSet()`  | ZSetOperations  | 操作`SortedSet`类型数据 |
>| redisTemplate                 |                 | 通用命令                |
>
>#### 依赖：SpringBoot已经默认整合了Redis并且做了自动装配，使用时只需引入依赖即可
>
>```xml
><!--    redis    -->
><dependency>
>    <groupId>org.springframework.boot</groupId>
>    <artifactId>spring-boot-starter-data-redis</artifactId>
></dependency>
><!--    连接池依赖    -->
><dependency>
>    <groupId>org.apache.commons</groupId>
>    <artifactId>commons-pool2</artifactId>
></dependency>
>```
>
>#### SpringBoot项目全局配置文件
>
>```yaml
>spring:
>  redis:
>    host: 192.168.85.150  # redis远程主机ip
>    port: 6379            # redis默认端口
>    username: default     # 采用默认用户
>    password:             # 默认用户无密码
>    database: 0           # 选择0号数据库
>    lettuce: # 配置lettuce连接池，spring默认为lettuce连接池
>      pool:
>        max-active: 8     # 最大连接数
>        max-idle: 8       # 最大空闲连接
>        min-idle: 0       # 最小空闲连接
>        max-wait: 100     # 连接等待时间
>```
>
>#### 测试类
>
>```java
>package com.mofany.test;
>
>import org.junit.jupiter.api.Test;
>import org.springframework.boot.test.context.SpringBootTest;
>import org.springframework.data.redis.core.RedisTemplate;
>
>import javax.annotation.Resource;
>
>/**
> * @author MoFany-J
> * @date 2023/3/5
> * @description RedisTest
> */
>@SpringBootTest
>public class RedisTest {
>    @Resource
>    private RedisTemplate redisTemplate;
>
>    /**
>     * 插入String类型数据
>     */
>    @Test
>    public void set() {
>        redisTemplate.opsForValue().set("name", "赵高");
>    }
>
>    /**
>     * 读取String类型数据
>     */
>    @Test
>    public void get() {
>        Object name = redisTemplate.opsForValue().get("name");
>        System.out.println(name);
>    }
>}
>```
>
>* 测试结果
>
>  ```properties
>  赵高
>  ```
>
>* ##### `但是出现了一个序列化问题，就是在redis控制台获取到的该key的值是一个不可识别字符串`
>
>#### lettuce的Hash操作
>
>```java
>/**
> * hash表存
> */
>@Test
>public void hashSet() {
>    // key field value
>    stringRedisTemplate.opsForHash().put("person:male", "name", "张三");
>    stringRedisTemplate.opsForHash().put("person:male", "age", "23");
>}
>
>/**
> * hash表取
> */
>@Test
>public void hashGet() {
>    Map<Object, Object> entries = stringRedisTemplate.opsForHash().entries("person:male");
>    System.out.println(entries);
>}
>```
>
>

## RedisTemplate的两种序列化实现方案

>#### 方案一：
>
>1. ##### 自定义`RedisTemplate`
>
>2. ##### 修改RedisTemplate的序列化器为`GenericJackson2JsonRedisSerializer`
>
>#### 方案二：
>
>1. ##### 使用`StringRedisTemplate`
>
>2. ##### 写入`Redis`时，手动将对象序列化为`Json`
>
>3. ##### 读取`Redis`时，手动将读取到的Json反序列化为对象

## :boxing_glove:方案一：`自动`序列化与反序列化

>#### RedisTemplate
>
>* ##### 可以接收任意Object作为值写入Reids，只不过写入前会将Object序列化为字节形式，默认是采用JDK序列化
>
>* 可读性差
>* 内存占用大
>
>#### 我们要实现所见即所得，即实现全自动序列化与反序列化`舍弃jdk序列化`
>
>* ##### key序列化一般用`StringRedisSerializer`
>
>* ##### value序列化一般用`GenericJackson2JsonRedisSerializer`
>
>```java
>package com.mofany.config;
>
>import org.springframework.context.annotation.Bean;
>import org.springframework.context.annotation.Configuration;
>import org.springframework.data.redis.connection.RedisConnectionFactory;
>import org.springframework.data.redis.core.RedisTemplate;
>import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;
>import org.springframework.data.redis.serializer.RedisSerializer;
>
>import javax.annotation.Resource;
>
>/**
> * @author MoFany-J
> * @date 2023/3/5
> * @description RedisConfiguration
> */
>@Configuration
>public class RedisConfiguration {
>    /**
>     * 自定义RedisTemplate序列化方式
>     */
>    @Bean
>    @Resource
>    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory connectionFactory) {
>        // 创建RedisTemplate实例
>        RedisTemplate<String, Object> redisTemplate = new RedisTemplate<>();
>        // 设置连接工厂
>        redisTemplate.setConnectionFactory(connectionFactory);
>        // 创建Json序列化工具
>        GenericJackson2JsonRedisSerializer jsonRedisSerializer = 
>            											new GenericJackson2JsonRedisSerializer();
>        
>        // key和hashKey采用String序列化
>        redisTemplate.setKeySerializer(RedisSerializer.string());
>        redisTemplate.setHashKeySerializer(RedisSerializer.string());
>        
>        // value和hashValue采用Json序列化
>        redisTemplate.setValueSerializer(jsonRedisSerializer);
>        redisTemplate.setHashValueSerializer(jsonRedisSerializer);
>        
>        // 返回
>        return redisTemplate;
>    }
>}
>```
>
>#### 测试
>
>* 实体类
>
>  ```java
>  package com.mofany.entity;
>  
>  import lombok.AllArgsConstructor;
>  import lombok.Data;
>  import lombok.NoArgsConstructor;
>  
>  import java.io.Serializable;
>  
>  /**
>   * @author MoFany-J
>   * @date 2023/3/5
>   * @description Student
>   */
>  @Data
>  @AllArgsConstructor
>  @NoArgsConstructor
>  public class Student implements Serializable {
>      private static final long serialVersionUID = -2262401866499884543L;
>      private String name;
>      private String sex;
>      private Integer age;
>  }
>  ```
>
>* 测试类
>
>  ```java
>  package com.mofany.test;
>  
>  import com.mofany.entity.Student;
>  import org.junit.jupiter.api.Test;
>  import org.springframework.beans.factory.annotation.Autowired;
>  import org.springframework.boot.test.context.SpringBootTest;
>  import org.springframework.data.redis.core.RedisTemplate;
>  
>  import javax.annotation.Resource;
>  
>  /**
>   * @author MoFany-J
>   * @date 2023/3/5
>   * @description RedisTest
>   */
>  @SpringBootTest
>  public class RedisTest {
>      /**
>      * 自动注入配置了自定义序列化的Bean
>      */
>      @Autowired
>      private RedisTemplate<String, Object> redisTemplate;
>      
>      /**
>       * 序列化存储对象
>       */
>      @Test
>      public void objSet() {
>          redisTemplate.opsForValue().set("student:1", new Student("路飞", "男", 22));
>      }
>  
>      /**
>       * 反序列化获取对象
>       */
>      @Test
>      public void objGet() {
>          System.out.println(redisTemplate.opsForValue().get("student:1"));
>      }
>  }
>  ```
>
>* 测试结果
>
>  * `objSet()`序列化对象`redis控制台`
>
>    ```json
>    {
>        "@class": "com.mofany.entity.Student",
>        "name": "路飞",
>        "sex": "男",
>        "age": 22
>    }
>    ```
>
>    * ***序列化带来了额外的开销！！！导致过度内存占用！！！***
>
>  * `objGet()`反序列化对象`idea控制台`
>
>    ```properties
>    Student(name=路飞, sex=男, age=22)
>    ```

## :boxing_glove:方案二：`手动`序列化与反序列化

>#### StringRedisTemplate
>
>* ##### spring默认提供了一个`StringRedisTemplate`类，它的key与value的序列化方式默认就是String方式，从而省去了我们自定义`RedisTemplate`序列化方式的过程
>
>* ###### 为了节省空间，我们并不会使用Json序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value，***当需要存储Java对象时，手动完成对象的序列化与反序列化***。
>
>#### 依赖引入
>
>```xml
><!-- 序列化与反序列化依赖 -->
><dependency>
>    <groupId>com.fasterxml.jackson.core</groupId>
>    <artifactId>jackson-databind</artifactId>
></dependency>
>```
>
>#### 手动序列化与反序列化
>
>```java
>package com.mofany.test;
>
>import com.fasterxml.jackson.core.JsonProcessingException;
>import com.fasterxml.jackson.databind.ObjectMapper;
>import com.mofany.entity.Student;
>import org.junit.jupiter.api.Test;
>import org.springframework.boot.test.context.SpringBootTest;
>import org.springframework.data.redis.core.StringRedisTemplate;
>
>import javax.annotation.Resource;
>
>/**
> * @author MoFany-J
> * @date 2023/3/5
> * @description StringRedisTemplateTest 手动序列化
> */
>@SpringBootTest
>public class StringRedisTemplateTest {
>    /**
>    * key与value的序列化方式默认为String
>    */
>    @Resource
>    private StringRedisTemplate stringRedisTemplate;
>    /**
>     * Json工具，ObjectMapper是SpringMVC里面默认的序列化工具
>     */
>    private static final ObjectMapper mapper = new ObjectMapper();
>
>    /**
>     * 手动序列化对象到redis
>     */
>    @Test
>    void writeObj() throws JsonProcessingException {
>        // 准备对象
>        Student obj = new Student("乔巴", "男", 18);
>        // 手动序列化
>        String objJson = mapper.writeValueAsString(obj);
>        // 将对象json字符串写入redis
>        stringRedisTemplate.opsForValue().set("student:2", objJson);
>    }
>
>    /**
>     * 从redis反序列对象
>     */
>    @Test
>    void readObj() throws JsonProcessingException {
>        // 从redis中读取对象json字符串
>        String objJson = stringRedisTemplate.opsForValue().get("student:2");
>        // 手动反序列化
>        Student obj = mapper.readValue(objJson, Student.class);
>        System.out.println(obj);
>    }
>}
>```
>
>* 测试结果
>
>  * `writeObj()`序列化对象`redis控制台`
>
>    ```json
>    {
>        "name": "乔巴",
>        "sex": "男",
>        "age": 18
>    }
>    ```
>
>  * `readObj()`反序列化对象`idea控制台`
>
>    ```properties
>    Student(name=乔巴, sex=男, age=18)
>    ```

## :boxing_glove:推荐方案：自定义工具类

>```java
>package com.mofany.util;
>
>import com.fasterxml.jackson.core.JsonProcessingException;
>import com.fasterxml.jackson.databind.ObjectMapper;
>import org.springframework.data.redis.core.StringRedisTemplate;
>
>/**
> * @author MoFany-J
> * @date 2023/3/6
> * @description SetOrGetObject 向redis中写入或从redis中读出一个对象
> */
>public class SetOrGetObject<T> {
>
>    /**
>     * 构造器注入
>     * */
>    private StringRedisTemplate stringRedisTemplate;
>    public SetOrGetObject(StringRedisTemplate stringRedisTemplate) {
>        this.stringRedisTemplate = stringRedisTemplate;
>    }
>
>    /**
>     * 序列化与反序列化
>     */
>    private WriteOrReadObj writeOrReadObj = new WriteOrReadObj();
>
>    /**
>     * 写json串
>     */
>    public void setObject(String key, T obj) throws JsonProcessingException {
>        // 序列化
>        String objJson = writeOrReadObj.writeObject(obj);
>        // 将序列化后的json对象写入redis
>        stringRedisTemplate.opsForValue().set(key, objJson);
>    }
>
>    /**
>     * 读json串
>     */
>    public T getObject(String key, Class<T> clazz) throws JsonProcessingException {
>        // 从redis中读出json对象进行反序列化
>        String objJson = stringRedisTemplate.opsForValue().get(key);
>        // 反序列化
>        T obj = writeOrReadObj.readObject(objJson, clazz);
>        return obj;
>    }
>
>    /**
>     * WriteOrReadObj 序列化与反序列化工具类
>     */
>    private class WriteOrReadObj {
>        /**
>         * Json工具，ObjectMapper是SpringMVC里面默认的序列化工具
>         */
>        private ObjectMapper mapper = new ObjectMapper();
>
>        /**
>         * 序列化对象
>         */
>        public String writeObject(T obj) throws JsonProcessingException {
>            String objJson = mapper.writeValueAsString(obj);
>            return objJson;
>        }
>
>        /**
>         * 反序列化对象
>         */
>        public T readObject(String objJson, Class<T> clazz) throws JsonProcessingException {
>            T obj = mapper.readValue(objJson, clazz);
>            return obj;
>        }
>    }
>}
>```
>
>#### 测试类
>
>```java
>package com.mofany.test;
>
>import com.fasterxml.jackson.core.JsonProcessingException;
>import com.mofany.entity.Student;
>import com.mofany.util.SetOrGetObject;
>import org.junit.jupiter.api.Test;
>import org.springframework.boot.test.context.SpringBootTest;
>import org.springframework.data.redis.core.StringRedisTemplate;
>
>import javax.annotation.Resource;
>
>
>/**
> * @author MoFany-J
> * @date 2023/3/5
> * @description StringRedisTemplateTest
> */
>@SpringBootTest
>public class StringRedisTemplateTest {
>    @Resource
>    private StringRedisTemplate stringRedisTemplate;
>    
>    /**
>     * 手动序列化对象到redis
>     */
>    @Test
>    void writeObj() throws JsonProcessingException {
>        SetOrGetObject<Student> setOrGetObject = new SetOrGetObject<>(stringRedisTemplate);
>        // 准备对象
>        Student obj = new Student("罗宾", "女", 28);
>        // 写入对象
>        setOrGetObject.setObject("student:3", obj);
>    }
>
>    /**
>     * 从redis反序列对象
>     */
>    @Test
>    void readObj() throws JsonProcessingException {
>        SetOrGetObject<Student> setOrGetObject = new SetOrGetObject<>(stringRedisTemplate);
>        // 获取对象
>        Student obj = setOrGetObject.getObject("student:3", Student.class);
>        System.out.println(obj);
>    }
>}
>```
>
>* 序列化后的对象
>
>  ```json
>  {
>      "name": "罗宾",
>      "sex": "女",
>      "age": 28
>  }
>  ```
>
>* 反序列化后的对象
>
>  ```properties
>  Student(name=罗宾, sex=女, age=28)
>  ```
>
>#### 缺点就是：`SetOrGetObject`只能是一个方法的局部变量时才有效果，否则`NPE`
>
>* 解决办法：
>  1. 由Spring管理的类使用`StringRedisTemplate`与`RedisTemplate`时，才能使用注解`@Autowired`、`Resource`进行自动注入
>  2. 而由我们自定义的工具类，若要使用`StringRedisTemplate`、`RedisTemplate`时必须进行构造器注入

# Redis缓存

## 缓存概述

>* ##### 缓存就是数据交换的缓冲区（称为Cache），其是存储数据的临时场所，其读写效率与性能比较高。
>
>* 缓存的作用：
>
>  * 降低后端负载
>  * 提高读写效率，降低响应时间
>
>* 缓存的成本：`缓存要保证高可用 AP`
>
>  * 数据一致性成本`Redis缓存中的数据与对应的数据库中的数据产生不一致冲突`
>  * 代码维护成本
>  * 运维成本
>

## :boxing_glove:缓存工作模型与实现

>#### 缓存工作模型
>
>* `*`代表数据库中有要查询的数据
>* `0`数据库中没有要查询的数据
>* `2.0`情况一：缓存命中
>* `2.a`情况二：缓存未命中
>
>```properties
>	+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>	|                   		Client (客户端)                                      |
>	+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>	           +                   ⋀                                   ▲
>	           |                   |   2.0                             |
>	     请求   |                   |  read cache                       |
>2. request |                   | success（命中：返回)                |    
>	           |                   |                                   |   2.c
>	           |                   |                                   | read database
>	           ⋁                   *                                   | success (2：发给客户端)
>	  + - - - - - - - - - - - - - - - - - - - - +                      |
>	  |   Cache （Redis 缓存)                    |                      |
>	  + - - - - - - - - - - - - - - - - - - - - +                      |
>	               		 O                   ▲                         |
>	               		 |                   |                         |
>	         2.a      	 |                   |      2.b                |
>	（未命中：读数据库)fail |                   | write cache（1：写缓存)   |
>	               		 |                   |                         |
>	               		 |                   |                         |
>	               		 ⋁                   *                         *
>	+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>	|                   		Database (数据库)                                    |
>	+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +   
>```
>
>#### 业务逻辑实现`店铺类型的查询缓存`：Reids直接做缓存
>
>```java
>@Service
>public class ShopTypeServiceImpl extends ServiceImpl<ShopTypeMapper, ShopType> implements IShopTypeService {
>
>    /**
>    * 当前项目的application.yaml中配置reids以及连接池 lettuce
>    * 项目启动时由spring容器管理的类会自动注入
>    */
>    @Resource
>    private StringRedisTemplate stringRedisTemplate;
>
>    /**
>     * 查询类型列表，使用reids中List类型
>     */
>    @Override
>    public Result queryTypeList() {
>        // 1.先从redis缓存中查询
>        String key = CACHE_SHOP_KEY + "type:list";
>        List<String> typeListStr = stringRedisTemplate.opsForList().range(key, 0, 1);
>        // 2.判断redis缓存中的数据，存在则直接返回
>        if (typeListStr != null && typeListStr.size() != 0) {
>            // 缓存中存在在直接返回
>            log.debug("缓存命中!!!");
>            List<ShopType> shopTypes = JSONUtil.toList(typeListStr.get(0), ShopType.class);
>            return Result.ok(shopTypes);
>        }
>        log.debug("缓存未命中!!!");
>        // 3.redis缓存中不存在时，则从数据库中查询
>        List<ShopType> typeList = query().orderByAsc("sort").list();
>        // 4.判断数据库中查询到的内容是否为空
>        if (typeList == null || typeList.size() == 0) {
>            // 为空则报错
>            return Result.fail("类型列表为空!");
>        }
>        // 5.不为空，则先写入缓存
>        stringRedisTemplate.opsForList().rightPushAll(key, JSONUtil.toJsonStr(typeList));
>        // 6.返回结果
>        return Result.ok(typeList);
>    }
>}
>```
>
>#### 最后缓存中的内容`按sort升序排序`
>
>```json
>[
>  {
>    "icon": "/types/ms.png",
>    "updateTime": 1640229871000,
>    "sort": 1,
>    "createTime": 1640175467000,
>    "name": "美食",
>    "id": 1
>  },
>  {
>    "icon": "/types/KTV.png",
>    "updateTime": 1640229871000,
>    "sort": 2,
>    "createTime": 1640175507000,
>    "name": "KTV",
>    "id": 2
>  },
>  {
>    "icon": "/types/lrmf.png",
>    "updateTime": 1640229871000,
>    "sort": 3,
>    "createTime": 1640175528000,
>    "name": "丽人·美发",
>    "id": 3
>  },
>  {
>    "icon": "/types/mjmj.png",
>    "updateTime": 1640229871000,
>    "sort": 4,
>    "createTime": 1640175706000,
>    "name": "美睫·美甲",
>    "id": 10
>  },
>  {
>    "icon": "/types/amzl.png",
>    "updateTime": 1640229871000,
>    "sort": 5,
>    "createTime": 1640175567000,
>    "name": "按摩·足疗",
>    "id": 5
>  }
>]
>```
>
>#### Redis做MyBatis的二级缓存
>
>

## :boxing_glove:缓存更新策略

>#### 内存淘汰策略
>
>* 不用自己维护，利用redis的`内存淘汰机制`，当内存不足时自动淘汰部分数据。下次查询时更新缓存。
>* 一致性：`差`
>* 维护成本：`无`
>
>#### 超时剔除策略
>
>* 给缓存数据`添加TTL时间`，到期后自动删除缓存，下次查询时更新缓存。
>* 一致性：`一般`
>* 维护成本：`低`
>
>#### 主动更新策略
>
>* 开发人员自己编写业务逻辑，在修改数据库的同时，更新缓存。
>
>  * `Cache Aside Pattern`
>
>    * ##### 由缓存的调用者，在更新数据库的同时更新缓存。:ballot_box_with_check:
>
>    * ##### 操作缓存与数据库时又会遇到三个问题：
>
>      1. ###### 删除缓存还是更新缓存？`保证数据一致`
>
>         * 更新缓存：每次更新数据库都更新缓存，无效写操作较多:negative_squared_cross_mark:
>         * 删除缓存：更新数据库时让缓存失效，查询时再更新缓存:ballot_box_with_check:
>
>      2. ###### 如何保证缓存与数据库的操作的同时成功或失败？`保证原子性`
>
>         * 单体系统：将缓存与数据库操作放在一个事务:ballot_box_with_check:
>         * 分布式系统：利用TCC等分布式事务方案:ballot_box_with_check:
>
>      3. ###### 先操作缓存还是先操作数据库？`并发安全问题会引发缓存与数据库数据不一致问题`
>
>         * ###### 先删除缓存，再操作数据库:negative_squared_cross_mark:
>
>           * 线程`t1`删除缓存，然后去更新数据库，但其更新数据库需要`200ms`；此时线程`t2`乘虚而入查询缓存但结果未命中，然后线程`t2`去查询数据库并将结果写入缓存后，线程`t1`才成功更新数据库，这时：
>
>             ###### `数据库数据（新数据）!= 缓存数据（旧数据）`高概率事件
>
>             ```properties
>             =================== 先删缓存，后操作数据库 ===================
>             
>             + - - - - - - - +						+ - - - - - - - +
>             |   线程：t1     |	                      |   线程：t2     |
>             + - - - - - - - +                       + - - - - - - - +
>                     +                                       + 
>                     |---+                                   |
>                     |   | 1.delete cache                    |
>                     |<--+                                   |
>                     |                                       |
>                     |                                       |
>                     |                                       |
>                     |                                       |---+   
>                     |                                       |   | 2.select cache:fail(0)
>                     |                                       |<--+   select database
>                     |                                       |       
>                     |                                       |
>                     |                                       |---+   
>                     |                                       |   | 3.weite cache
>                     |                                       |<--+   
>                     |                                       |
>                     |                                       |
>                     |                                       |
>                     |                                       |
>                     |---+                                   |
>                     |   | 4.update cache                    |
>                     |<--+     data = 20                     |
>                     |                                       |
>                     V                                       V    
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                |        Cache             |          10          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +    1
>                |        Database          |          10          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                                       |       |
>                                       |       |
>                                       V       V        
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                |        Cache             |                      |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +    2、3
>                |        Database          |          10          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                                       |       |
>                                       |       |
>                                       V       V
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                |        Cache : old       |          10          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +    4
>                |        Database : new    |          20          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>             ```
>
>         * ###### 先操作数据库，再删除缓存:ballot_box_with_check:
>
>           * 在某一时刻下恰好缓存失效了，线程`t1`访问缓存时未命中，就去数据库中查询然后写入缓存，但写缓存需要耗时`200us`；此时在线程`t2`更新完数据库并删除缓存后，线程`t1`才成功写入缓存，这时：
>
>             ###### `数据库数据（新数据）!= 缓存数据（旧数据）`低概率事件
>
>             ```properties
>             =================== 先操作数据库，后删缓存 ===================
>             
>             + - - - - - - - +						+ - - - - - - - +
>             |   线程：t1     |	                      |   线程：t2     |
>             + - - - - - - - +                       + - - - - - - - +
>                     +                                       +
>                     |---+                                   |
>                     |   | 1.select cache:fail(0)            |
>                     |<--+   select database                 |
>                     |                                       |
>                     |                                       |
>                     |                                       |
>                     |                                       |---+   
>                     |                                       |   | 2.update database
>                     |                                       |<--+   data = 20
>                     |                                       |       
>                     |                                       |
>                     |                                       |---+   
>                     |                                       |   | 3.delete cache
>                     |                                       |<--+   
>                     |                                       |
>                     |                                       |
>                     |                                       |
>                     |                                       |
>                     |---+                                   |
>                     |   | 4.write cache                     |
>                     |<--+                                   |
>                     |                                       |
>                     V                                       V       
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                |        Database          |          10          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +    1
>                |        Cache             |        time out      |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                                       |       |
>                                       |       |
>                                       V       V        
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                |        Database          |          20          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +    2、3
>                |        Cache             |                      |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                                       |       |
>                                       |       |
>                                       V       V
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>                |        Database : new    |          20          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +    4
>                |        Cache : old       |          10          |
>                + - - - - - - - - - - - - - - - - - - - - - - - - +
>             ```
>
>           * ##### 解决方案：`在写缓存的时候加一个超时时间`
>
>  * `Read/Write Through Pattern`
>
>    * 缓存与数据库整合为一个服务，由服务来维护一致性。调用者调用该服务，无需关心缓存一致性问题。
>
>  * `Write Behind Caching Pattern`
>
>    * 调用者只操作缓存，由其它线程异步的将缓存数据持久化到数据库，保证最终一致。
>
>* 一致性：`好`
>
>* 维护成本：`高`
>
>### 缓存更新策略最佳实践方案：
>
>* ##### 低一致性需求：使用Redis自带的内存淘汰机制。
>
>* ##### 高一致性需求：主动更新，并以超时剔除作为兜底方案。
>
>  1. ###### 读操作
>
>     * 缓存命中则直接返回
>     * 缓存未命中则查询数据库，并写入缓存，设定超时时间:ballot_box_with_check:
>
>  2. ###### 写操作
>
>     * 先写数据库，然后再删除缓存:ballot_box_with_check:
>     * 要确保数据库与缓存操作的原子性
>
>#### 业务逻辑实现`更新商铺信息`：单体系统缓存一致性保证
>
>* ##### 实现的策略：`当数据库数据更新的时,将缓存中的对应数据移除`
>
>  ```java
>  /**
>  * 商铺信息更新的业务逻辑
>  */
>  @Override
>  @Transactional
>  public Result update(Shop shop) {
>      // 校验id
>      Long id = shop.getId();
>      if (id == null) {
>          return Result.fail("店铺id不能为空!");
>      }
>      // 1.先更新数据库
>      updateById(shop);
>      // 2.后删除缓存
>      stringRedisTemplate.delete(CACHE_SHOP_KEY + id);
>      return Result.ok();
>  }
>  ```
>
>* 请求发起的接口及数据
>
>  ```http
>  http://localhost:8081/shop
>  ```
>
>  ```json
>  {
>      "area":"大关",
>      "openHours":"10:00-22:00",
>      "sold":4215,
>      "address":"金华路锦昌文化苑29号",
>      "comments":3035,
>      "avgPrice":80,
>      "score":37,
>      "name":"102茶餐厅",
>      "typeId":1,
>      "id":1
>  }
>  ```
>
>* ##### 最终结论：
>
>  * ###### 当商铺信息更新后将对应的Redis的缓存移除！！！
>
>  * ###### 此时我们已经实现了数据库与缓存的数据同步！！！

## :boxing_glove:缓存穿透

>#### 缓存穿透问题
>
>* ##### 指客户端请求的数据在缓存与数据库中都不存在，这样缓存永远不会生效，而这些请求都会打到数据库上
>
>  ```properties
>  ====================== 缓存穿透：都不存在 ======================
>  
>  			+ - - - - - - - - - - - - - - - - +
>  			|            Client               |
>  			+ - - - - - - - - - - - - - - - - +
>  			       +                      ⋀
>  			       |                      |
>  			       | 1.request            |
>  			       |   未命中              |
>  			       |                      |
>  			       V                      |
>  			+ - - - - - - - - +           |
>  			|   Redis Cache   |          NULL  3.return NULL  
>  			+ - - - - - - - - +           |
>  			       0                      |
>  			       |                      |
>  			       | 2.select database    |
>  			       |      未命中           |
>  			       |                      |    
>  			       V                      0
>  			+ - - - - - - - - - - - - - - - - +
>  			|            Database             |
>  			+ - - - - - - - - - - - - - - - - +
>  ```
>
>* 别有用心之人会反向利用这一点，并发访问某一个压根不存在的请求，当大量不存在的并发请求打到数据库时容易使数据库宕机。
>
>#### 解决缓存穿透问题的方案：
>
>1. 缓存空对象
>
>   * 即使请求的内容不存在，则将数据库返回的 NULL`缓存空对象的时候设一个短TTL过期时间` 也写入缓存中
>
>   * `缺点：`
>
>     * 显而易见，其会带来额外的内存消耗`加TTL`
>     * 可能造成短期的数据不一致问题`控制TTL的时间，会缓解`
>
>   * 解决方法：`若当前请求在新增数据的时，我们可以将该数据写入数据库的时候一并更新缓存，覆盖缓存旧数据`
>
>     ```properties
>     ====================== 缓存空对象 ======================
>     
>     			+ - - - - - - - - - - - - - - - - +
>     			|            Client               |
>     			+ - - - - - - - - - - - - - - - - +
>     			       +                      
>     			       |                      
>              1.request |             
>                 未命中  |           
>     			       |                      
>     			       V                      
>     			+ - - - - - - - - - - - - - - +           
>     			|        Redis Cache          |              
>     			+ - - - - - - - - - - - - - - +           
>     			       0                    ⋀
>     			       |                    |
>      2.select database |                   NULL
>     	    未命中      |              3.缓存中写入空对象
>     			       |                    |    
>     			       V                    0
>     			+ - - - - - - - - - - - - - - - - +
>     			|            Database             |
>     			+ - - - - - - - - - - - - - - - - +
>     ```
>
>2. 布隆过滤
>
>   * 在客户端与Reids缓存中间又加入了一层`布隆过滤器`用来判别客户端的请求是否有效，有效则放行，无效请求则直接拒绝。
>
>   * 布隆过滤器中存储的是二进制的位，将数据基于某一种算法算出Hash值，再将Hash值按位存储到布隆过滤器。
>
>   * `优点`：内存占用少，没有多余的key
>
>   * `缺点`：
>
>     * 实现复杂
>     * 存在误判
>
>     ```properties
>     ====================== 布隆过滤器 ======================
>     
>     			+ - - - - - - - - - - - - - - - - +
>     			|            Client               |
>     			+ - - - - - - - - - - - - - - - - +
>     			 +             ⋀         ⋀      ⋀
>        1.request |1.1 not pass |         |      |
>     			 V             +         |      |
>     			+ - - - - - - - +        |      |
>     			|   布隆过滤器    | 2.1 cache   database 2.c    
>     			+ - - - - - - - +        |      |
>     			       +                 |      |
>             request	   |                 |      |
>         2.success pass |                 -RETURN-
>                        |                 |      |
>     			       |                 |      |
>     			       V                 +      |
>     			+ - - - - - - - - - - - - - +   |        
>     			|        Redis Cache        |   |           
>     			+ - - - - - - - - - - - - - +   |        
>     			       0              ⋀         |
>     			       |              |         |
>     2.a selectDatabase |      2.b writeCache    |
>     	    未命中      |              |         |
>     			       |              |         |   
>     			       V              +         +
>     			+ - - - - - - - - - - - - - - - - +
>     			|            Database             |
>     			+ - - - - - - - - - - - - - - - - +
>     ```

### :gem::gem:利用缓存空对象解决缓存穿透问题

>* ##### 查询商铺解决缓存击穿
>
>* ##### 采用策略：`缓存空对象`
>
>```java
>@Override
>public Result queryById(Long id) {
>    // 1.从redis中查询商铺缓存
>    String key = CACHE_SHOP_KEY + id;
>    String shopJson = stringRedisTemplate.opsForValue().get(key);
>    // 2.判断缓存中是否存在，非空值判断
>    if (StrUtil.isNotBlank(shopJson)) {
>        // 3.缓存命中，则直接返回
>        log.debug("缓存命中!有效值！");
>        Shop shop = JSONUtil.toBean(shopJson, Shop.class);
>        return Result.ok(shop);
>    }
>    /**
>     * 命中的是否是空值
>     * */
>    if (shopJson != null) {
>        // 返回错误信息
>        log.debug("缓存命中!无效值！");
>        return Result.fail("店铺不存在!");
>    }
>    // 4.不存在，根据id查询数据库
>    log.debug("缓存未命中!");
>    Shop shop = getById(id);
>    /**
>     * 将空值写入 Redis 缓存
>     * */
>    if (shop == null) {
>        // 缓存空对象
>        stringRedisTemplate.opsForValue().set(key, "", CACHE_NULL_TTL, TimeUnit.MINUTES);
>        // 返回错误信息
>        return Result.fail("店铺不存在!");
>    }
>    // 6.存在，写缓存
>    stringRedisTemplate.opsForValue()
>        			.set(key, JSONUtil.toJsonStr(shop), CACHE_SHOP_TTL, TimeUnit.MINUTES);
>    // 7.返回
>    return Result.ok(shop);
>}
>```
>
>* 此时当我们查询一个不存在的信息时，做出如下响应
>
>  * ###### 此时Redis缓存中缓存了一个键为key的有过期时间的空键值对！！！
>
>  ```http
>  http://localhost:8080/api/shop/0
>  ```
>
>  ```json
>  {
>    "success": false,
>    "errorMsg": "店铺不存在!"
>  }
>  ```
>
>* ##### 这样就解决了缓存穿透问题！！！
>
>* ##### 这样减小了后台数据库的压力，此时数据库对于并发访问某个不存在的请求时，直接走缓存空对象`在缓存有效期内`，不会再去查询数据库！！！
>
>#### 总结
>
>* ##### 缓存穿透产生的主要原因以及影响？
>
>  * ###### 用户请求的数据在缓存中和数据库中都不存在，不断发起这样的请求，给数据库带来巨大的压力
>
>* 缓存穿透的解决方案有哪些？
>
>  1. 缓存null值`短暂的不一致以及额外的内存开销`
>  2. 布隆过滤`过滤的准确性有一定的缺点且实现过于复杂`
>  3. 增强id的复杂度，避免被猜出id规律
>  4. 做好数据的基础格式校验
>  5. 加强用户权限校验
>  6. 做好热点参数的限流

## :boxing_glove:缓存雪崩

>#### 缓存雪崩问题
>
>* ##### 在同一时段下大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，为数据库带来巨大压力
>
>  ###### 1.大量缓存key失效
>
>  ```properties
>  ====================== 缓存雪崩：大量key失效 ======================
>  
>  			+ - - - - - - - - - - - - - - - - +
>  			|            Client               |
>  			+ - - - - - - - - - - - - - - - - +
>  			    +  +  +                      
>  			    |  |  |                      
>  			    | ... | 1.request            
>  			    |  |  |   未命中              
>  			    |  |  |                      
>  			    V  V  V                      
>  			+ - - - - - - - - +           
>  			|   Redis Cache   |  100万条缓存key同时失效     
>  			+ - - - - - - - - +           
>  			    0  0  0                      
>  			    |  |  |                      
>  			    | ... | 2.select database    
>  			    |  |  |           
>  			    |  |  |                         
>  			    V  V  V                      
>  			+ - - - - - - - - - - - - - - - - +
>  			|            Database             |
>  			+ - - - - - - - - - - - - - - - - +
>  ```
>
>  ###### 2.Redis服务器宕机
>
>  ```properties
>  ====================== 缓存雪崩：Redis服务器宕机 ======================
>  
>  			+ - - - - - - - - - - - - - - - - +
>  			|            Client               |
>  			+ - - - - - - - - - - - - - - - - +
>  			    +  +  +                      
>  			    |  |  |                      
>  			    | ... | 1.request            
>  			    |  |  |   未命中              
>  			    |  |  |                      
>  			    |  |  |                      
>  			+ - | -|- | - - - +           
>  			|   | ... |       |  Redis服务器宕机     
>  			+ - | -| -| - - - +           
>  			    |  |  |                  
>  			    |  |  |                      
>  			    | ... | 2.select database    
>  			    |  |  |           
>  			    |  |  |                         
>  			    V  V  V                      
>  			+ - - - - - - - - - - - - - - - - +
>  			|            Database             |
>  			+ - - - - - - - - - - - - - - - - +
>  ```
>
>#### 解决方案
>
>1. ##### 给不同的`Key`指定随机的`TTL`，以免大量`Key`同时失效，`分散Key的过期时间`
>
>2. ##### 利用Redis集群提高服务的高可用
>
>   * 利用Redis集群的哨兵机制`主挂了，选举另一个Master`
>   * 利用Redis集群的主从复制机制`每一个服务都与Master的数据同步`
>
>3. ##### 给缓存业务添加降级与限流策略
>
>4. ##### 给业务添加多级缓存
>
>   * 反向代理服务器`Nginx`层面做缓存
>   * 也可以在`JVM`中建立本地缓存

## :boxing_glove:缓存击穿

>#### 缓存击穿问题：
>
>* ##### 其也成为热点`Key`问题，就是一个被`高并发访问`并且`缓存重建业务比较复杂`的`Key`突然失效了，无数的请求会在瞬间给数据库带来巨大冲击。
>
>  ```properties
>  ====================== 缓存击穿：部分热点Key失效 ======================
>  
>        线程：t1                     线程：t2                      线程：t3       
>  + - - - - - - - - +          + - - - - - - - - +          + - - - - - - - - +
>  |       t1        |          |       t2        |          |       t3        |      
>  + - - - - - - - - +          + - - - - - - - - +          + - - - - - - - - +
>          +                             +                            +
>          |- +                          |                            |
>          |  | 1.select cache           |                            |
>          |  |      fail:0              |                            |
>          |<-+                          |- +                         |- +
>          |                             |  | 1.select cache          |  | 1.select cache
>          |- +                          |  |      fail:0             |  |      fail:0   
>          |  |                          |<-+                         |<-+
>          |  | 2.select database        |                            |
>          |  |   rebuild cache          |- +                         |- +
>          |  |                          |  |                         |  |
>          |  |                          |  | 2.select database       |  | 2.select database
>          |  |                          |  |   rebuild cache         |  |   rebuild cache  
>          |  |                          |  |                         |  |
>          |<-+                          |  |                         |  |
>          |                             |  |                         |  |
>          |- +                          |  |                         |  |
>          |  | 4.write cache            |  |                         |  |
>          |<-+                          |<-+                         |<-+
>  ```
>
>#### 常见解决方案
>
>* ##### 互斥锁:negative_squared_cross_mark:
>
>  * 某个线程获取到互斥锁后重新构建缓存需要`200ms`，则在该线程构建成功写入缓存，释放互斥锁之前；其余线程都得阻塞等待，这样会导致性能降低，耗时比较长。
>
>* ##### 逻辑过期:ballot_box_with_check:
>
>  * ###### `key：value`键值对，现在我们给`value`中再添加一个`expire过期时间字段`，使用的时候我们给热点给的value字段添加逻辑过期时间字段，使用结束的时候必须移除value中 该逻辑过期时间字段。
>
>  * 在互斥锁基础上构建的新方案，当前获取锁的父线程安排另外一个子线程去帮忙构建缓存，而父线程则返回缓存内的旧数据；在构建过程中若有其它线程也来获取锁准备构建缓存，由于互斥锁被其它线程占用，则当前线程不等待不阻塞而是之间返回缓存中原来的旧数据。
>
>| 解决方案 | 优点                                     | 缺点                                       |
>| -------- | ---------------------------------------- | ------------------------------------------ |
>| 互斥锁   | 没有额外的内存消耗，保证一致性，实现简单 | 线程需要等待，性能受影响，可能有死锁的风险 |
>| 逻辑过期 | 线程无需等待，性能较好                   | 不保证一致性，有额外内存消耗，实现复杂     |

### :gem::gem:利用互斥锁解决缓存击穿问题

>* ##### 加锁：选择Redis中自带的命令实现互斥操作，该命令的作用就是若key不存在则创建key-value，若存在则该命令无效。
>
>  * redis互斥操作一：（非原子性）`setnx key value 与 expire seconds`
>  * redis互斥操作二：（具有原子性）`set key value ex seconds nx`
>
>  ```java
>  /**
>   * 添加锁
>   */
>  private boolean tryLock(String key) {
>      // 值
>      String value = "1";
>      // 有效期
>      int expire = 10;
>      // 执行Redis中的setnx操作
>      Boolean result = 
>          stringRedisTemplate.opsForValue().setIfAbsent(key, value, expire, TimeUnit.SECONDS);
>      return BooleanUtil.isTrue(result);
>  }
>  ```
>
>* ##### 释放锁：`del key`，直接删除该`key`从而方便另外一个线程创建。
>
>  ```java
>  /**
>   * 释放锁
>   */
>  private void unLock(String key) {
>      // 删除以该key为主的键值对
>      stringRedisTemplate.delete(key);
>  }
>  ```
>
>#### 互斥锁解决缓存穿透问题
>
>```java
>/**
>* 修改根据id查询商铺的业务，基于互斥锁方式来解决缓存击穿问题
>*/
>public Shop queryWithMutex(Long id) {
>    String key = CACHE_SHOP_KEY + id;
>    // 1.从redis中查询商铺缓存
>    String shopJson = stringRedisTemplate.opsForValue().get(key);
>    // 2.判断缓存中是否存在，空白内容校验
>    if (StrUtil.isNotBlank(shopJson)) {
>        // 3.缓存命中，则直接返回
>        log.debug("缓存命中!有效值!");
>        return JSONUtil.toBean(shopJson, Shop.class);
>    }
>    // 命中的是否是空值
>    if (shopJson != null) {
>        // 返回错误信息
>        log.debug("缓存命中!无效值!");
>        return null;
>    }
>    /**
>     * 未命中开始实现缓存重建，获取互斥锁
>     * */
>    log.debug("缓存未命中!");
>    String lockKey = "lock:shop:" + id;
>    Shop shop = null;
>    try {
>        boolean isLock = tryLock(lockKey);
>        // 4.2判断是否获取成功
>        if (!isLock) {
>            // 4.3 失败，则休眠并重试
>            Thread.sleep(50);
>            // 递归，睡醒之后重新获取锁
>            return queryWithMutex(id);
>        }
>        // 4.4获取成功，根据id查询数据库
>        shop = getById(id);
>        // TODO 休眠，模拟重建缓存时的延时
>        Thread.sleep(200);
>        // 将空值写入 Redis 缓存
>        if (shop == null) {
>            // 缓存空对象，到redis
>            stringRedisTemplate.opsForValue().set(key, "", CACHE_NULL_TTL, TimeUnit.MINUTES);
>            // 返回错误信息
>            return null;
>        }
>        // 6.存在，写缓存
>        stringRedisTemplate.opsForValue()
>            			.set(key, JSONUtil.toJsonStr(shop), CACHE_SHOP_TTL, TimeUnit.MINUTES);
>    } catch (InterruptedException e) {
>        e.printStackTrace();
>    } finally {
>        // 7.释放互斥锁
>        unLock(lockKey);
>    }
>    // 8.返回
>    return shop;
>}
>```
>
>* ##### 高并发场景下该业务逻辑只会触发一次数据库查询，其它线程在看到当前锁被占用时一直处于阻塞等待状态

### :gem::gem:利用逻辑过期解决缓存击穿问题

>* ##### 加锁：`setnx key value ex seconds`reis语法
>
>  ```java
>  /**
>   * 添加锁
>   */
>  private boolean tryLock(String key) {
>      // 值
>      String value = "1";
>      // 有效期
>      int expire = 10;
>      // 执行Redis中的setnx操作
>      Boolean result = 
>          stringRedisTemplate.opsForValue().setIfAbsent(key, value, expire, TimeUnit.SECONDS);
>      return BooleanUtil.isTrue(result);
>  }
>  ```
>
>* ##### 释放锁：`del key`redis语法
>
>  ```java
>  /**
>   * 释放锁
>   */
>  private void unLock(String key) {
>      // 删除以该key为主的键值对
>      stringRedisTemplate.delete(key);
>  }
>  ```
>
>* ##### 逻辑过期时间的格式：`key:value => key：{data+expire}`
>
>  ```java
>  /**
>  * value封装类
>  */
>  @Data
>  public class RedisData {
>      /**
>      * 真正要存入redis的数据
>      */
>      private Object data;
>      
>      /**
>      * 逻辑过期时间
>      */
>      private LocalDateTime expireTime;
>  }
>  ```
>
>* ##### 将数据以及逻辑过期时间写入Redis缓存
>
>  ```java
>  public void saveShop2Redis(Long id, Long expireSeconds) {
>      // 1.查询店铺数据
>      Shop shop = getById(id);
>      // 模拟时延
>      Thread.sleep(200);
>      // 2.封装逻辑过期时间
>      RedisData redisData = new RedisData();
>      redisData.setData(shop);
>      redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds));
>      // 3.写入Redis
>      stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData));
>  }
>  ```
>
>  * 单元测试类
>
>    ```java
>    @SpringBootTest
>    class ApplicationTests {
>        @Resource
>        private ShopServiceImpl shopService;
>    
>        @Test
>        void testSaveShop() {
>            shopService.saveShop2Redis(1L, 10L);
>        }
>    }
>    ```
>
>  * 单元测试结果
>
>    ```json
>    {
>        "data": {
>            "area": "大关",
>            "openHours": "10:00-22:00",
>            "sold": 4215,
>            "images": "https://qcloud.dpfile.com/pc/jiclIs...._8ZGOT1OjpJmLxG6urQ.jpg",
>            "address": "金华路锦昌文化苑29号",
>            "comments": 3035,
>            "avgPrice": 80,
>            "updateTime": 1678264545000,
>            "score": 37,
>            "createTime": 1640167839000,
>            "name": "102茶餐厅",
>            "x": 120.149192,
>            "y": 30.316078,
>            "typeId": 1,
>            "id": 1
>        },
>        "expireTime": 1678299988886 // 逻辑过期时间
>    }
>    ```
>
>#### 逻辑过期解决缓存穿透问题
>
>* ##### 热点数据使用时写缓存，热点数据使用结束时将写入缓存数据的逻辑过期字段删除
>
>```java
>/**
> * 创建线程池，（建议采用该方法，一定不要手动的new线程池）
> */
>private static int threadNums = 0;
>
>private static ExecutorService getThreadsExecutor() {
>    // 线程池7大核心参数
>    ThreadPoolExecutor threadPool = new ThreadPoolExecutor(
>            // 线程池常驻线程数
>            10,
>            // 线程池最大线程数
>            20,
>            // 空闲线程存活时间
>            50,
>            // 时间单位：毫秒
>            TimeUnit.MILLISECONDS,
>            // 线程阻塞队列
>            new ArrayBlockingQueue<Runnable>(10),
>            // 自定义线程工厂
>            runnable -> new Thread(runnable, "线程" + threadNums++),
>            // 线程拒绝策略
>            new ThreadPoolExecutor.AbortPolicy()
>    );
>    return threadPool;
>}
>
>/**
> * 逻辑过期解决缓存穿透
> */
>public Shop queryWithLogicalExpire(Long id) {
>    String key = CACHE_SHOP_KEY + id;
>    // 1.从redis中查询商铺缓存
>    String shopJson = stringRedisTemplate.opsForValue().get(key);
>    // 2.判断缓存不存在返回空
>    if (StrUtil.isBlank(shopJson)) {
>        return null;
>    }
>    // 命中，需要先将Json反序列化为对象
>    RedisData redisData = JSONUtil.toBean(shopJson, RedisData.class);
>    // 获取json中的实体数据
>    JSONObject data = (JSONObject) redisData.getData();
>    Shop shop = JSONUtil.toBean(data, Shop.class);
>    // 获取json中的逻辑过期时间
>    LocalDateTime expireTime = redisData.getExpireTime();
>    // 判断缓存数据是否过期
>    if (expireTime.isAfter(LocalDateTime.now())) {
>        // 过期时间如果在当前时间之后，未过期，直接返回信息
>        log.debug("缓存命中!");
>        return shop;
>    }
>	// 逻辑时间已过期，即未命中
>    log.debug("缓存未命中!");
>    String lockKey = LOCK_SHOP_KEY + id;
>    /**
>    * 获取锁，redis的setnx语法
>    */ 
>    boolean isLock = tryLock(lockKey);
>    // 判断是否成功获取锁
>    if (isLock) {
>        // 将要执行的任务交给线程池中的子线程执行，无返回值的提交
>        getThreadsExecutor().submit(() -> {
>            try {
>                // 缓存重建
>                log.debug("重建缓存!");
>                this.saveShop2Redis(id, 20L);
>            } catch (Exception e) {
>                throw new RuntimeException(e);
>            } finally {
>                /**
>                *  释放锁
>                */
>                unLock(lockKey);
>            }
>        });
>    }
>    // 失败，直接返回过期商铺信息
>    return shop;
>}
>```

## :boxing_glove:缓存工具封装

>#### 封装一个工具类，满足如下需求
>
>1. ###### 将任意java对象序列化为json并存储在String类型的key中，并且可以值当TTL过期时间
>
>2. ###### 将任意java对象序列化为json并存储在String类型的key中，并且可以指定过期时间，用于处理缓存击穿问题
>
>3. ###### 根据指定的key查询缓存，并反序列化为指定类型，利用缓存空值的方式解决缓存穿透问题`1-3普通缓存穿透问题`
>
>4. ###### 根据指定的key查询缓存，并反序列化为指定类型，需要利用逻辑过期解决缓存击穿问题`2-4热点key击穿问题`
>
>#### 数据与逻辑过期的封装
>
>```java
>import lombok.Data;
>
>import java.time.LocalDateTime;
>
>@Data
>public class RedisData {
>    private LocalDateTime expireTime;
>    private Object data;
>}
>```
>
>#### 工具类封装
>
>```java
>package com.mofany.utils;
>
>import cn.hutool.core.util.BooleanUtil;
>import cn.hutool.core.util.StrUtil;
>import cn.hutool.json.JSONObject;
>import cn.hutool.json.JSONUtil;
>import lombok.extern.slf4j.Slf4j;
>import org.springframework.data.redis.core.StringRedisTemplate;
>import org.springframework.stereotype.Component;
>
>import javax.annotation.Resource;
>import java.time.LocalDateTime;
>import java.util.concurrent.*;
>import java.util.function.Function;
>
>/**
> * @author MoFany-J
> * @date 2023/3/9
> * @description CacheClient 缓存问题解决工具类
> */
>@Slf4j
>@Component
>public class CacheClient {
>    @Resource
>    private StringRedisTemplate stringRedisTemplate;
>
>    /**
>     * 写redis
>     *
>     * @param key   键
>     * @param value 值
>     * @param time  时间
>     * @param unit  单位
>     */
>    public void set(String key, Object value, long time, TimeUnit unit) {
>        stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(value), time, unit);
>    }
>
>    /**
>     * 逻辑过期
>     *
>     * @param key   键
>     * @param value 值
>     * @param time  时间
>     * @param unit  单位
>     */
>    public void setWithLogicalExpire(String key, Object value, long time, TimeUnit unit) {
>        // 设置逻辑过期
>        RedisData redisData = new RedisData();
>        redisData.setData(value);
>        redisData.setExpireTime(LocalDateTime.now().plusSeconds(unit.toSeconds(time)));
>        // 写入redis
>        stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(redisData));
>    }
>
>    /**
>     * 利用缓存空对象解决缓存穿透
>     *
>     * @param <R>             返回值泛型
>     * @param <ID>            数据库查询参数泛型
>     * @param keyPrefix       key前缀
>     * @param id              数据库查询参数
>     * @param clazz           返回值类型
>     * @param dbQueryFunction 数据库查询功能逻辑（函数式编程）
>     * @param time            时间
>     * @param unit            单位
>     */
>    public <R, ID> R queryWithPassThrough(
>            String keyPrefix, ID id, Class<R> clazz,
>            Function<ID, R> dbQueryFunction, long time, TimeUnit unit) {
>        
>        // 从redis中查询商铺缓存
>        String key = keyPrefix + id;
>        String json = stringRedisTemplate.opsForValue().get(key);
>        // 判断缓存中是否存在，非空值判断
>        if (StrUtil.isNotBlank(json)) {
>            // 缓存命中，则直接返回
>            log.debug("缓存命中!有效值！");
>            return JSONUtil.toBean(json, clazz);
>        }
>        // 命中的是否是空值
>        if (json != null) {
>            // 返回错误信息
>            log.debug("缓存命中!无效值！");
>            return null;
>        }
>        // 不存在，根据id查询数据库
>        log.debug("缓存未命中!");
>        // TODO 注意是实现数据库的操作
>        R result = dbQueryFunction.apply(id);
>        /**
>         * 将空值写入 Redis 缓存
>         * */
>        if (result == null) {
>            // 缓存空对象
>            stringRedisTemplate.opsForValue().set(key, "", time, unit);
>            return null;
>        }
>        // 存在，写缓存
>        this.set(key, result, time, unit);
>        // 返回
>        return result;
>    }
>
>    /**
>     * 利用逻辑过期解决缓存击穿
>     *
>     * @param <R>             返回类型的泛型
>     * @param <ID>            id泛型
>     * @param keyPrefix       key前缀
>     * @param id              id 要查询的依赖
>     * @param clazz           传入的类型
>     * @param dbQueryFunction 数据库查询功能逻辑（函数式编程）
>     * @param time            时间
>     * @param unit            单位
>     */
>    public <R, ID> R queryWithLogicalExpire(
>            String keyPrefix, ID id, Class<R> clazz,
>            Function<ID, R> dbQueryFunction, long time, TimeUnit unit) {
>
>        String key = keyPrefix + id;
>        // 从redis中获取缓存
>        String shopJson = stringRedisTemplate.opsForValue().get(key);
>        // 判断缓存不存在返回空
>        if (StrUtil.isBlank(shopJson)) {
>            log.debug("缓存未命中!");
>            return null;
>        }
>        // 命中，需要先将Json反序列化为对象
>        RedisData redisData = JSONUtil.toBean(shopJson, RedisData.class);
>        // 获取json中的实体数据，并反序列化为对象
>        R result = JSONUtil.toBean((JSONObject) redisData.getData(), clazz);
>        // 获取json中的逻辑过期时间
>        LocalDateTime expireTime = redisData.getExpireTime();
>        // 判断缓存数据是否过期
>        if (expireTime.isAfter(LocalDateTime.now())) {
>            // 过期时间如果在当前时间之后，未过期，直接返回信息
>            log.debug("缓存命中!未过期!" + expireTime);
>            return result;
>        }
>        /**
>         * 逻辑时间已过期开始实现缓存重建，获取互斥锁
>         * */
>        log.debug("缓存命中!已过期!");
>        String lockKey = "local:key:" + id;
>        // 获取锁，redis的setnx语法
>        boolean isLock = tryLock(lockKey);
>        // 判断是否成功获取锁
>        if (isLock) {
>            // 将要执行的任务交给线程池中的子线程执行
>            getThreadsExecutor().submit(() -> {
>                try {
>                    // 查数据库
>                    R value = dbQueryFunction.apply(id);
>                    // 写redis
>                    log.debug("重建缓存!");
>                    // 缓存重建，即更新当前热点key
>                    this.setWithLogicalExpire(key, value, time, unit);
>                } finally {
>                    // 释放锁
>                    unLock(lockKey);
>                }
>            });
>        }
>        // 失败，直接返回
>        return result;
>    }
>
>    /**
>     * 创建线程池
>     */
>    private static ExecutorService getThreadsExecutor() {
>        int threads = 10;
>        // 线程池7大核心参数
>        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(
>                // 线程池常驻线程数
>                threads,
>                // 线程池最大线程数
>                threads << 1,
>                // 空闲线程存活时间
>                500,
>                // 时间单位：毫秒
>                TimeUnit.MILLISECONDS,
>                // 线程阻塞队列，链表
>                new LinkedBlockingQueue<>(),
>                // 自定义线程工厂
>                runnable -> new Thread(runnable),
>                // 线程拒绝策略，调用者线程帮忙执行
>                new ThreadPoolExecutor.CallerRunsPolicy()
>        );
>        return threadPool;
>    }
>
>    /**
>     * 获取锁
>     *
>     * @param key 加锁的key
>     */
>    private boolean tryLock(String key) {
>        // 执行Redis中的setnx操作，过期时间为10秒，当发生异常该锁未能释放时，根据有效期自动释放
>        Boolean result = stringRedisTemplate.opsForValue()
>            					.setIfAbsent(key, "default Lock!", 10, TimeUnit.SECONDS);
>        return BooleanUtil.isTrue(result);
>    }
>
>    /**
>     * 释放锁
>     *
>     * @param key 释放锁的key
>     */
>    private void unLock(String key) {
>        stringRedisTemplate.delete(key);
>    }
>}
>```
>
>* ##### 首先必须将该：`数据+逻辑过期`写入Redis缓存，再进入下一步测试

## :boxing_glove:Redis做MyBatis的缓存

> #### 依赖
>
> ```xml
> <dependency>
>     <groupId>org.mybatis.caches</groupId>
>     <artifactId>mybatis-redis</artifactId>
>     <version>1.0.0</version>
> </dependency>
> ```
>
> #### 在对应的`Mapper`的`.xml`配置文件中添加配置
>
> ```xml
> <mapper namespace="org.acme.FooMapper">
> 	<cache type="org.mybatis.caches.redis.RedisCache"/>
>     ...
> </mapper>
> ```
>
> #### 配置`redis.properties`
>
> ```properties
> host=127.0.0.1
> port=6379
> # default用户无密码
> password= 
> # 最大活动
> maxActive=100
> # 最大空闲
> maxIdle=20
> # 耗尽时的动作
> whenExhaustedAction=WHEN_EXHAUSTED_GROW
> # 最大等待
> maxWait=10
> # 采用测试
> testOnBorrow=true
> # 返回测试
> testOnReturn=true
> # 两次回收的时间间隔（ms）
> timeBetweenEvictionRunsMillis=10000
> # 每次清除运行的测试数
> numTestsPerEvictionRun=10000
> # 最小可回收空闲时间
> minEvictableIdleTimeMillis=100
> # 
> softMinEvictableIdleTimeMillis=-1
> ```
>
> #### 在方法的形参前加final 关键字，是为了避免形参的值在方法体中被修改
>
> #### `RedisCache`类
>
> - 该类实现了`Cache`接口并使用`Jedis`客户端操作Redis，在RedisCache构造器中建立了与Redis的连接
>
>   ```java
>   /**
>   * 源代码
>   */
>   public RedisCache(final String id){
>       if(id == null){
>           throw new IllegalArgumentExceotion("Cache instances require an ID");
>       }
>       this.id = id;
>       // 通过RedisConfigurationBuilder对象获取Redis配置信息
>       redisConfig = RedisConfigurationBuilder.getInstance().parseConfiguration();
>       // 实例化JedisPool，与Redis服务器建立连接
>       pool = new JedisPool(
>           redisConfig,
>           redisConfig.getHost(), // 主机
>           redisConfig.getPort(), // 端口
>           redisConfig.getConnectionTimeout(), // 连接超时
>           redisConfig.getSoTimeout(), // 暂停时间
>           redisConfig.getPassword(), // 密码
>           redisConfig.getDatabase(), // 数据库
>           redisConfig.getClientName(), // 客户端名
>           redisConfig.isSsl(),
>           redisConfig.getSslSocketFactory(),
>           redisConfig.getSslParameters(),
>           redisConfig.getHostnameVerifier()
>       );
>   }
>   ```
>
> #### `RedisCache`的序列化与反序列化
>
> - 序列化`putObject()`
>
>   ```java
>   /**
>   * 序列化
>   */
>   @Override
>   public void putObject(final Object key,final Object value){
>       execute(new RedisCallback(){
>           @Override
>           public Object doWithRedis(Jedis jedis){
>               final byte[] idBytes = id.getBytes();
>               jedis.hset(idBytes,
>                          key.toString().getBytes(),
>                          redisConfig.getSerializer().serialize(value));
>               if (timeout != null && jedis.ttl(idBytes) == -1){
>                   // 设置有效期
>                   jedis.expire(idBytes,timeout);
>               }
>               return null;
>           }
>       });
>   }
>   ```
>
> - 反序列化`getObject()`
>
>   ```java
>   /**
>   * 反序列化
>   */
>   @Override
>   public Object getObject(final Object key){
>       return execute(new RedisCallback(){
>           @Override
>           public Object doWithRedis(Jedis jedis){
>               return redisConfig.getSerializer().unserialize(
>                   jedis.hget(id.getBytes(),key.toString().getBytes())
>               );
>           }
>       });
>   }
>   ```

# Redis实际应用

## :boxing_glove:全局唯一ID

>* 全局id生成器：其是一种在分布式系统下用来生成`全局唯一ID`的工具，要满足以下特性：
>  1. 唯一性
>  2. 高可用
>  3. 高性能
>  4. 递增性`incrby key increment命令实现单调递增`
>  5. 安全性`我们要保证id的安全性，即增加id复杂性`
>
>#### 全局唯一ID生成策略
>
>* ##### UUID
>
>* ##### 数据库自增
>
>* ##### snowflake算法`雪花算法`
>
>* ##### Redis自增

### :gem::gem:利用`redis自增`ID生成策略实现全局唯一ID

>#### Redis自增
>
>* 为了增加ID的安全性，我们可以不直接使用Redis自增的数值，而是拼接一些其它信息
>
>  ##### `符号位(1bit) + 时间戳(31 bit) + 序列号(32bit)`
>
>  * 符号位：1bit，永远为0
>  * 时间戳：31bit，以秒为单位，可以使用69年
>  * 序列号：32bit，秒内的计数器，支持每秒产生2^32个不同ID
>
>```javascript
>package com.mofany.utils;
>
>import org.springframework.data.redis.core.StringRedisTemplate;
>import org.springframework.stereotype.Component;
>
>import javax.annotation.Resource;
>import java.time.LocalDateTime;
>import java.time.ZoneOffset;
>import java.time.format.DateTimeFormatter;
>
>/**
> * @author MoFany-J
> * @date 2023/3/9
> * @description RedisIdWorker 基于redis自增的id生成策略实现
> */
>@Component
>public class RedisIdWorker {
>
>    @Resource
>    StringRedisTemplate stringRedisTemplate;
>
>    /**
>     * 开始的时间戳，秒数，2023-02-20
>     */
>    private static final long BEGIN_TIMESTAMP = 1676822400L;
>
>    /**
>     * 序列号位数
>     */
>    private static final int COUNT_BITS = 32;
>
>    /**
>     * 返回id
>     *
>     * @param keyPrefix 不同业务的key前缀
>     */
>    public long nextId(String keyPrefix) {
>        LocalDateTime nowDateTime = LocalDateTime.now();
>        long currentTimestamp = nowDateTime.toEpochSecond(ZoneOffset.UTC);
>        // 生成时间戳
>        long timestamp = currentTimestamp - BEGIN_TIMESTAMP;
>        // 生成序列号，日期以冒号为分隔符，这样存储在Redis中便于按年月日分别统计
>        String nowDate = nowDateTime.format(DateTimeFormatter.ofPattern("yyyy:MM:dd"));
>        String key = "icr:" + keyPrefix + ":" + nowDate;
>        /**
>        * 自增长key，单个key自增长上限为：2^6，redis数据库中记录了总的id生成数
>        */ 
>        Long increment = stringRedisTemplate.opsForValue().increment(key);
>        // long类型拼接并返回
>        long GloballyUniqueId = timestamp << COUNT_BITS | increment;
>        // 全局唯一id格式：符号位1bit + 时间戳31bit + 序列号32bit
>        return GloballyUniqueId;
>    }
>}
>```
>
>* 测试类
>
>  ```java
>  @SpringBootTest
>  class ApplicationTests {
>  
>      /**
>       * 简单的线程池
>       */
>      private static final ExecutorService THREAD_EXECUTOR = Executors.newFixedThreadPool(500);
>  
>      @Resource
>      private RedisIdWorker redisIdWorker;
>  
>      /**
>       * 全局唯一id单元测试
>       */
>      /**
>       * 全局唯一id单元测试
>       */
>      @Test
>      public void test() throws InterruptedException {
>          // 使一个线程等待其他线程完成各自的工作后再执行
>          CountDownLatch latch = new CountDownLatch(300);
>          // 线程要做的任务
>          Runnable task = () -> {
>              try {
>                  for (int i = 0; i < 100; i++) {
>                      // 同一秒内生成的id前缀一致
>                      long id = redisIdWorker.nextId("order");
>                      System.out.println("id = " + id);
>                  }
>              } finally {
>                  // 每一个线程执行完，就倒计时直到为0为止
>                  latch.countDown();
>              }
>          };
>          // 开启计时
>          long beginTime = System.currentTimeMillis();
>          // 提交任务
>          for (int i = 0; i < 300; i++) {
>              THREAD_EXECUTOR.submit(task);
>          }
>          // 等待所有线程完成
>          latch.await();
>          // 所有线程执行完成后计时
>          long endTime = System.currentTimeMillis();
>          System.out.println("time = " + (endTime - beginTime));
>      }
>  }
>  ```
>
>* 测试结果
>
>  ```properties
>  # ....
>  id = 6801699188815885
>  id = 6801699188815886
>  id = 6801699188815887
>  id = 6801699188815888
>  id = 6801699188815890
>  id = 6801699188815889
>  id = 6801699188815891
>  id = 6801699188815893
>  id = 6801699188815892
>  id = 6801699188815894
>  id = 6801699188815896
>  id = 6801699188815895
>  time = 64352
>  # 居然耗时6秒钟，生成344334个全局唯一id
>  ```

## :boxing_glove:Redis`优惠卷`秒杀

>#### `后端`响应所有优惠卷信息
>
>1. ###### `公共ID`：所有优惠卷都拥有一个同值的`public id`字段，该字段用于查询所有优惠卷信息作为一个数组响应给前端
>
>2. ###### `私有id`：每一个不同的优惠卷又拥有一个自己的`private id`，用于抢购时向后端进行请求反馈
>
>#### `前端`过滤待展示的优惠卷
>
>1. ###### `普通卷`：前端对于类型为普通卷的优惠卷则一致显示，保持时刻都有
>
>2. ###### `秒杀卷`：前端对于类型为限量秒杀的优惠卷则要进行有效期的判断，保证只显示在有效期内的秒杀优惠卷
>
>#### 优惠卷秒杀下单时需要判断两点：
>
>1. ###### 秒杀释放开始或结束，如果尚未开始或已经 结束则无法下单
>
>2. ###### 库存是否充足，不足则无法下单
>
>3. ###### 这些操作都要用到每个秒杀卷的`私有id`
>
>#### 优惠卷下单功能实现
>
>```java
>/**
> * 秒杀卷库存表操作业务逻辑
> */
>@Resource
>private ISeckillVoucherService seckillVoucherService;
>
>/**
> * 注入全局唯一ID生成器
> */
>@Resource
>private RedisIdWorker redisIdWorker;
>
>@Override
>@Transactional
>public Result seckillVoucher(Long voucherId) {
>    // 查询优惠卷
>    SeckillVoucher voucher = seckillVoucherService.getById(voucherId);
>    // 判断秒杀是否开始，开始时间在当前时间之后
>    if (voucher.getBeginTime().isAfter(LocalDateTime.now())) {
>        return Result.fail("秒杀尚未开始!");
>    }
>    // 判断秒杀是否结束，开始时间在当前时间之前
>    if (voucher.getEndTime().isBefore(LocalDateTime.now())) {
>        return Result.fail("秒杀已经结束!");
>    }
>    // 判断库存是否充足，库存小于1
>    if (voucher.getStock() < 1) {
>        return Result.fail("库存不足!");
>    }
>    // 扣减库存
>    boolean success = seckillVoucherService.update()
>            .setSql("stock = stock - 1")
>            .eq("voucher_id", voucherId).update();
>    if (!success) {
>        return Result.fail("库存不足!");
>    }
>    // 创建订单
>    VoucherOrder voucherOrder = new VoucherOrder();
>    // 生成订单id
>    long orderId = redisIdWorker.nextId("order");
>    // 设置订单id
>    voucherOrder.setId(orderId);
>    // 获取用户id
>    Long userId = UserHolder.getUser().getId();
>    // 设置用户id
>    voucherOrder.setUserId(userId);
>    // 设置秒杀卷id
>    voucherOrder.setVoucherId(voucherId);
>    // 将订单写入数据库
>    save(voucherOrder);
>    // 返回订单id
>    return Result.ok(orderId);
>}
>```
>
>#### 在这里由于设置了拦截器：`前置拦截器`
>
>* ##### 使用JMeter进行并发压力测试的时候，一定要配置请求头：`authorization对应的值，即用户Token`
>
>#### 高并发秒杀下商品库存发生了超卖`并发安全问题`
>
>* **库存为`1`的时：**线程`t1`查询了库存，但还未成功扣减库存；此时线程`t2`又进来查询了库存，此时线程`t1`与`t2`查到的库存数是一样的，都为`1`。最后线程`t1`与`t2`分别进行了库存扣减，**最后导致商品库存数为负数**。
>
>```properties
>====================== 高并发秒杀场景 : 商品库存超卖 ======================
>
>
>      线程：t1              					       线程：t2                 
>+ - - - - - - - - +      					    + - - - - - - - - +      
>|       t1        |      					    |       t2        |      
>+ - - - - - - - - +      					    + - - - - - - - - +      
>        +                					             +               
>        |- +             					             |               
>        |  | 1.select inventory(查库存)          		   |               
>        |  |    inventory > 0    					     |               
>        |<-+             					             |         
>        |                					             |
>        |                					             |- +   
>        |                					             |  | 1. select inventory(查库存)         
>        |               					             |  |      inventory > 0        
>        |               					             |<-+   
>        |                                                |      在该时段之上查到的都是查旧数据
>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
>        |- +               					             |      在该时段之下则减了两次库存
>        |  |              					             |
>        |  | 2. --inventory(减库存)    				   |
>        |<-+      inventory: 0      					 |
>        |               					             |
>        |                                                |- +   
>        |                                                |  | 2. --inventory(减库存)
>        |                					             |  |      inventory: -1
>        |                					             |<-+   
>        |                                                |
>        V                                                V
>+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>|                    Default Inventory = 1                        |
>+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>        |
>        | 线程: t1 减库存后
>        |
>        V
>+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>|                    Default Inventory = 0                        |
>+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>                                                         |
>                                                         | 线程: t2 减库存后
>                                                         |
>                                                         V
>+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>|                    Default Inventory = -1                       |
>+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +
>             并发秒杀秒发场景下库存出现了负数，即发生了超卖
>```

### :gem::gem:利用乐观锁解决高并发秒杀场景下库存超卖

>1. ###### 加锁
>
>   * 悲观锁：认为线程安全问题一定会发生，因此在操作数据之前先获取锁，以确保线程串行执行
>
>     * `synchronized`互斥锁，内置锁，可重入锁，重量级锁
>     * `Lock`重量锁、可重入锁
>       * 公平锁
>       * 读写锁
>     * `优点：`简单粗暴
>     * `缺点：`性能略低
>
>   * 乐观锁：认为线程安全问题不一定会发生，因此不加锁，只是在更新数据时去判断有没有其它线程对数据做了修改
>
>     * 如果没有修改则认为是线程安全的，自己才更新数据
>
>     * 如果已经被其它线程修改说明发生了线程安全问题，此时可以重试或抛异常
>
>     * `优点：`高性能
>
>     * ###### `缺点：`存在成功率低的问题
>
>   * 分段锁：在只单纯判断数据有没有变化的情况下使用，`细粒度锁`
>
>     * ###### `优点:`高性能、解决了功能率低的问题
>
>     * `缺点：`实现复杂
>
>#### 选用乐观锁
>
>* ##### 乐观锁主要的问题是如何判断之前查询到的数据是否被修改过，常用方式有两种：
>
>  1. ###### 版本号法：给数据字段加一个版本，每当数据成功修改一次其版本号就加1
>
>  2. ###### CAS法：利用数据本身有没有变化去判断线程是否安全`削去了版本号`
>
>#### 乐观锁CAS法，解决商品库存超卖
>
>```java
>/**
> * 秒杀卷库存业务逻辑
> */
>@Resource
>private ISeckillVoucherService seckillVoucherService;
>
>/**
> * 注入id生成器
> */
>@Resource
>private RedisIdWorker redisIdWorker;
>
>@Override
>@Transactional
>public Result seckillVoucher(Long voucherId) {
>    // 查询优惠卷
>    SeckillVoucher voucher = seckillVoucherService.getById(voucherId);
>    // 判断秒杀是否开始，开始时间在当前时间之后
>    if (voucher.getBeginTime().isAfter(LocalDateTime.now())) {
>        return Result.fail("秒杀尚未开始!");
>    }
>    // 判断秒杀是否结束，开始时间在当前时间之前
>    if (voucher.getEndTime().isBefore(LocalDateTime.now())) {
>        return Result.fail("秒杀已经结束!");
>    }
>    // 判断库存是否充足，库存小于1
>    if (voucher.getStock() < 1) {
>        return Result.fail("库存不足!");
>    }
>    
>    /**
>     * @implNote 
>     * 扣减库存，利用了乐观锁CAS原理，比较并交换
>     * 使用了修改SQL的方法，来达到CAS乐观锁原理
>     * */
>    boolean success = seckillVoucherService.update()
>            // set stock = stock - 1
>            .setSql("stock = stock - 1")
>            // where id = ? and stock > 0
>            .eq("voucher_id", voucherId).gt("stock", 0)
>            .update();
>    
>    // 扣减库存失败
>    if (!success) {
>        return Result.fail("库存不足!");
>    }
>    // 创建订单
>    VoucherOrder voucherOrder = new VoucherOrder();
>    // 生成订单id
>    long orderId = redisIdWorker.nextId("order");
>    // 给订单设置订单id
>    voucherOrder.setId(orderId);
>    // 获取用户id
>    Long userId = UserHolder.getUser().getId();
>    // 给订单设置用户id
>    voucherOrder.setUserId(userId);
>    // 给订单设置优惠卷id
>    voucherOrder.setVoucherId(voucherId);
>    // 将订单写入数据库
>    save(voucherOrder);
>    // 返回订单id
>    return Result.ok(orderId);
>}
>```
>
>* 在JMeter中进行响应断言配置，让其将请求响应结果中`Success`的与`Fail`进行区分
>
>#### 最后使用JMeter测试200个秒杀请求样本的聚合报告中异常率达到`50%`时符合标准：
>
>| Label       | # 样本 | 平均值 | 中位数 | 90% 百分位 | 95% 百分位 | 99% 百分位 | 最小值 | 最大值 | 异常 % | 吞吐量   | 接收 KB/sec | 发送 KB/sec |
>| ----------- | ------ | ------ | ------ | ---------- | ---------- | ---------- | ------ | ------ | ------ | -------- | ----------- | ----------- |
>| HTTP   请求 | 200    | 988    | 1130   | 1223       | 1240       | 1260       | 334    | 1265   | 50.00% | 152.3229 | 31.98       | 41.06       |
>| 总体        | 200    | 988    | 1130   | 1223       | 1240       | 1260       | 334    | 1265   | 50.00% | 152.3229 | 31.98       | 41.06       |
>
>

### :gem::gem:利用悲观锁解决高并发秒杀场景下一人一单

>#### 秒杀业务：一个用户同一张优惠卷只能下一单
>
>#### 依赖配置
>
>* 依赖
>
>  ```xml
>  <!--第三方切面-->
>  <dependency>
>      <groupId>org.aspectj</groupId>
>      <artifactId>aspectjweaver</artifactId>
>  </dependency>
>  ```
>
>* 核心配置类`主启动类注解`
>
>  ```java
>  // 开启AspectJ自动代理
>  @EnableAspectJAutoProxy(exposeProxy = true)
>  ```
>
>#### 实现
>
>```java
>/**
>* Java动态代理必须的接口
>*/
>public interface IVoucherOrderService extends IService<VoucherOrder> {
>
>    /**
>    * 秒杀优惠卷
>    */
>    Result seckillVoucher(Long voucherId);
>
>    /**
>    * 创建优惠卷订单
>    */
>    Result createVoucherOrder(Long voucherId);
>}
>```
>
>```java
>@Service
>public class VoucherOrderServiceImpl extends ServiceImpl<VoucherOrderMapper, VoucherOrder> implements IVoucherOrderService {
>
>    /**
>     * 秒杀卷库存业务逻辑
>     */
>    @Resource
>    private ISeckillVoucherService seckillVoucherService;
>
>    /**
>     * 注入id生成器
>     */
>    @Resource
>    private RedisIdWorker redisIdWorker;
>
>    @Override
>    public Result seckillVoucher(Long voucherId) {
>        // 查询优惠卷
>        SeckillVoucher voucher = seckillVoucherService.getById(voucherId);
>        // 判断秒杀是否开始，开始时间在当前时间之后
>        if (voucher.getBeginTime().isAfter(LocalDateTime.now())) {
>            return Result.fail("秒杀尚未开始!");
>        }
>        // 判断秒杀是否结束，开始时间在当前时间之前
>        if (voucher.getEndTime().isBefore(LocalDateTime.now())) {
>            return Result.fail("秒杀已经结束!");
>        }
>        // 判断库存是否充足，库存小于1
>        if (voucher.getStock() < 1) {
>            return Result.fail("库存不足!");
>        }
>
>        // 获取用户id
>        Long userId = UserHolder.getUser().getId();
>        /**
>         * @implNote 同一个用户加同一把锁，不同用户加不同锁
>         * 必须确保先提交事务最后释放锁，所以才锁定用户的id字符串常量池返回的值
>         * */
>        synchronized (userId.toString().intern()) {
>            // 防止事务失效，获取当前代理类接口的代理对象
>            IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
>            // 通过当前类代理对象去调用方法，以防止事务失效
>            return proxy.createVoucherOrder(voucherId);
>        }
>    }
>
>    /**
>     * 一人一单，我们要确保先提交事务最后释放锁
>     */
>    @Override
>    @Transactional
>    public Result createVoucherOrder(Long voucherId) {
>        // 获取用户id
>        Long userId = UserHolder.getUser().getId();
>        // 查询订单
>        int count = query().eq("user_id", userId).eq("voucher_id", voucherId).count();
>        // 判断下单用户是否已经存在
>        if (count > 0) {
>            return Result.fail("当前用户已下过一次单!");
>        }
>        /**
>         * @implNote 扣减库存，利用了乐观锁CAS原理，比较并交换
>         * 使用了修改SQL的方法，来达到CAS乐观锁原理
>         * */
>        boolean success = seckillVoucherService.update()
>                // set stock = stock - 1
>                .setSql("stock = stock - 1")
>                // where id = ? and stock > 0
>                .eq("voucher_id", voucherId).gt("stock", 0)
>                .update();
>        // 扣减库存失败
>        if (!success) {
>            return Result.fail("库存不足!");
>        }
>        // 创建订单
>        VoucherOrder voucherOrder = new VoucherOrder();
>        // 生成订单id
>        long orderId = redisIdWorker.nextId("order");
>        // 给订单设置订单id
>        voucherOrder.setId(orderId);
>        // 给订单设置用户id
>        voucherOrder.setUserId(userId);
>        // 给订单设置优惠卷id
>        voucherOrder.setVoucherId(voucherId);
>        // 将订单写入数据库
>        save(voucherOrder);
>        // 返回订单id
>        return Result.ok(orderId);
>    }
>}
>```
>
>#### JMeter并发秒杀测试结果：`实现了一用户一订单`
>
>| Label       | # 样本 | 平均值 | 中位数 | 90% 百分位 | 95% 百分位 | 99% 百分位 | 最小值 | 最大值 | 异常 % | 吞吐量  | 接收 KB/sec | 发送 KB/sec |
>| ----------- | ------ | ------ | ------ | ---------- | ---------- | ---------- | ------ | ------ | ------ | ------- | ----------- | ----------- |
>| HTTP   请求 | 200    | 493    | 516    | 693        | 725        | 760        | 173    | 855    | 99.50% | 232.288 | 53.28       | 62.61       |
>| 总体        | 200    | 493    | 516    | 693        | 725        | 760        | 173    | 855    | 99.50% | 232.288 | 53.28       | 62.61       |
>
>#### 数据库订单表
>
>```properties
>mysql> select id,user_id,create_time,update_time from tb_voucher_order;
>+------------------+---------+---------------------+---------------------+
>| id               | user_id | create_time         | update_time         |
>+------------------+---------+---------------------+---------------------+
>| 7190247699906572 |    1010 | 2023-03-11 01:01:50 | 2023-03-11 01:01:50 |
>+------------------+---------+---------------------+---------------------+
>1 row in set (0.00 sec)
>```
>
>#### 总结：
>
>* ##### 以悲观锁锁对象的方式解决了一人一单的并发安全问题`只能使用于在单机情况下,集群项目下依然会产生并发安全问题`
>
>* 锁的原理：JVM内部维护了一个锁监视器对象，该监视器对象监视锁对象的UUID
>
>* `synchronized内置锁`只能实现同一个JVM下的锁互斥，而不能实现多个JVM进程间的锁互斥
>
>* 单机项目下对应一个JVM，而多个线程同一个用户锁在JVM内部的锁监视器中的UUID也唯一，故能互斥，也能解决单机项目的并发安全
>
>  ```properties
>  ==================== 单JVM内的锁监视器：单体项目 ====================
>  
>  
>                           JVM内锁监视器: 时刻1
>                          + - - - - - - - - +    
>  						|  Lock Monitor   |
>  						+ - - - - - - - - +
>  						|        t1       |
>  						+ - - - - - - - - +
>  					   /          |         
>  					 /            |           
>                     /              |              
>        线程：t1    /       			|		            线程：t2                 
>  + - - - - - - - - +      		  |			    + - - - - - - - - +      
>  |       t1        |      		  |			    |       t2        |      
>  + - - - - - - - - +      		  |			    + - - - - - - - - +      
>          +                		  |			             +               
>          |- +             		  |			             |- +                  
>          |  | 1.get Lock: success  |                      |  | 1.get Lock: fail               
>          |  |                      |   				     |  |                  
>          |<-+             		  |			             |<-+               
>          |                		  |			             |
>          |- +                      |                      |\
>          |  |              		  |			             | \
>          |  |              		  |			             |  \
>          |  | 2.operation 		  |			             |   \ 
>          |  |             		  |			             |    \
>          |  |                      |                      |     \
>          |  |                      |                      |      \
>          |<-+                      |                      |       \
>          |                         |                      |        \ 2.blocking 阻塞
>          |- +                      |                      |      /    
>          |  |                      |                      |    /    
>          |  | 3.free Lock          |                      |  /    
>          |<-+                      |                      |/   
>          |                         |                      |- +             		
>                                    |                      |  | 3.afresh get Lock: success
>                                    |                      |  |                    
>                                    |                      |<-+
>                                    |                      |
>                                    |                     /      
>                                    |                   /    
>                                    |                 /      
>                                    |               /        
>                                    |             /          
>                                    |           /            
>                                    V         /              
>                          + - - - - - - - - +              
>                          |  Lock Monitor   |                                  
>                          + - - - - - - - - +                                  
>                          |        t2       |
>                          + - - - - - - - - +
>                           JVM内锁监视器: 时刻2
>  ```
>
>* ##### *但是在集群项目下，每一个项目分别对应各自的JVM，而每个JVM中的锁监视器又不同，即同一个发起请求对象的锁对应了不同JVM的锁监视器，每个锁监视器注册了同一个对象锁；但在逻辑上又操作的是同一张表，故在同一个用户的多次请求下集群版的项目依然产生了并发安全问题*
>
>  ```properties
>  ==================== 多JVM内的锁监视器：集群项目 ====================
>  						
>   JVM进程p1内锁监视器                                JVM进程p2内锁监视器
>  + - - - - - - - - +                             + - - - - - - - - +  
>  |  Lock Monitor   |                             |  Lock Monitor   |
>  + - - - - - - - - +                             + - - - - - - - - +
>  |     p1：t1      |<- - +                       |     p2：t1       |<-  +
>  + - - - - - - - - +     |                       + - - - - - - - - +    |
>  					    |                                              |                   
>      JVM进程：p1          |					          JVM进程：p2         |        
>  + - - - - - - - - +     | 					    + - - - - - - - - +    |  
>  |      p1：t1     |-  - +     				   |       p2：t1     |- - +      
>  + - - - - - - - - +      					    + - - - - - - - - +      
>          +                					             +               
>          |- +             					             |- +                  
>          |  | 1.get Lock: success                         |  | 1.get Lock: success 
>          |  |                         				     |  |                  
>          |<-+             					             |<-+               
>          |                					             |
>          |- +                                             |- +            
>          |  |              					             |  |            
>          |  |              					             |  |             
>          |  | 2.operation 					             |  | 2.operation   
>          |  |             					             |  |               
>          |  |                                             |  |                
>          |  |                                             |  |                 
>          |<-+                                             |<-+                  
>          |                                                |  
>          |- +                                             |- +                     
>          |  |                                             |  |                  
>          |  | 3.free Lock                                 |  | 3.free Lock    
>          |<-+                                             |<-+               
>          |                                                |
>  ```
>

# 分布式

## :boxing_glove:分布式锁

> #### 分布式锁：
>
> * ##### 满足分布式系统或集群模式下多进程可见并且互斥的锁。
>
> * 分布式锁必须满足的特点：
>
>   1. 多进程可见：`Redis`、`MySql`、`Zookeeper`
>   2. 互斥：`多进程互斥`
>   3. 高可用：`易获取锁`
>   4. 高性能：`高并发`
>   5. 安全性
>
> #### 分布式锁其实是跨集群项目的、跨JVM的或跨进程的锁实现方式
>
> * **`JVM内部的锁监视器：`（用于实现同一个JVM进程内部各个线程之间的互斥操作）**一个JVM内部只有一个锁监视器，只会有一个线程获取锁可以实现线程之间的互斥；
>
> * **`JVM外部的锁监视器：`（用于实现不同JVM进程之间的互斥操作）**但是在有多个JVM的时候，就会有多个锁监视器，也就有多个线程获取到锁，这样就没有办法实现多JVM进程之间的互斥了，而此时我们就不能再去使用JVM内部的锁监视器，我们必须保证让多个JVM进程都去使用同一个锁监视器这样才能实现多JVM进程间的互斥，该锁监视器一定是在JVM外部的且能被多JVM进程所发现的锁监视器。
>
>   ```properties
>   ==================== JVM外的锁监视器：集群项目 ==================== 
>   
>                                  JVM外锁监视器
>                           + - - - - - - - - - - - +    
>   						|  Global Lock Monitor  |
>   						+ - - - - - - - - - - - +
>   						|        p1：t1         |
>   						+ - - - - - - - - - - - +
>   					   /                   
>   					 /                       
>                      /                            
>        JVM进程：p1  /       					          JVM进程：p2                 
>   + - - - - - - - - +      					    + - - - - - - - - +      
>   |      p1：t1     |      					   |       p2：t1     |      
>   + - - - - - - - - +      					    + - - - - - - - - +      
>           +                					             +               
>           |- +             					             |- +                  
>           |  | 1.get Lock: success                         |  | 1.get Lock: fail               
>           |  |                         				     |  |                  
>           |<-+             					             |<-+               
>           |                					             |
>           |- +                                             |\
>           |  |              					             | \
>           |  |              					             |  \
>           |  | 2.operation 					             |   \ 
>           |  |             					             |    \
>           |  |                                             |     \
>           |  |                                             |      \
>           |<-+                                             |       \
>           |                                                |        \ 2.blocking 阻塞
>           |- +                                             |      /    
>           |  |                                             |    /    
>           |  | 3.free Lock                                 |  /    
>           |<-+                                             |/   
>           |                                                |
>   ```
> #### 分布式锁实现`其核心是实现多进程互斥`
>
> |        | MySQL                | Redis                                    | Zookeeper                        |
> | ------ | -------------------- | ---------------------------------------- | -------------------------------- |
> | 互斥   | 利用mysql本身        | 利用`setnx`这样的互斥命令                | 利用节点的唯一性和有序性实现互斥 |
> | 高可用 | 好`支持主从模式`     | 好`支持主从与集群`                       | 好                               |
> | 高性能 | 一般`受限于自身性能` | 好                                       | 一般                             |
> | 安全性 | 断开连接，自动释放锁 | 利用Redis中key的过期时间，到期自动释放锁 | 临时节点，断开连接自动释放       |

### :gem::gem:利用Redis互斥锁机制实现分布式锁

> #### 基于Reids的分布式锁原理
>
> * ##### 获取锁
>
>   * ###### 互斥：确保只能有一个获取锁`setnx创建的key-value只能存在一个，其存在时其它创建则失效`
>
>     ```sql
>     -- 添加锁，利用 setnx 的互斥特性，语法：setnx key value
>     setnx lock thread
>     ```
>
> * ##### 获取锁后服务器宕机`宕机后过期则自动释放锁`
>
>   * ##### `此时该锁永久存在，而获取该锁的其余线程则陷入了阻塞状态中，此时业务就陷入了死锁状态中`
>
>   * ##### 解决方案：
>
>     * 手动释放
>
>     * ##### 超时释放：`添加锁时指定一个超时时间`
>
>       ```sql
>       -- 添加锁，利用了 setnx 的互斥特性
>       setnx key value
>       
>       -- 添加锁过期时间，避免因服务器宕机而引发的死锁，该过期时间应该比实际业务执行时间略长一些
>       expire key seconds
>       ```
>
>     * ##### 但是`setnx`操作与`expire`操作并非原子操作，若服务器宕机发生于两者之间依然会造成死锁
>
>       * ###### 具有原子操作的`setnx`，互斥锁机制
>
>       * ###### 非阻塞式，即尝试一次，成功返回`true`，失败返回`false`
>
>       ```sql
>       -- 具有原子操作的setnx与expire的结合
>       set key value ex seconds nx
>       ```
>
> * ##### 释放锁
>
>   * ###### 手动释放锁`即删除key对应的key-value`
>
>     ```sql
>     -- 释放锁，删除即可，语法：del key
>     del lock
>     ```
>
<<<<<<< HEAD
> #### 基于Redis的分布式锁实现
=======
> #### 基于Redis的分布式锁实现:negative_squared_cross_mark:
>>>>>>> origin
>
> * ###### 分布式锁接口
>
>   ```java
>   package com.mofany.utils;
>   /**
>    * @author MoFany-J
>    * @date 2023/3/15
>    * @description ILock 分布式锁获取接口
>    */
>   public interface ILock {
>       /**
>        * 尝试获取锁
>        *
>        * @param timeoutSec 锁持有的超时时间，过期自动释放
>        * @return true代表获取锁成功，false代表获取锁失败
>        */
>       boolean tryLock(long timeoutSec);
>   
>       /**
>        * 锁释放
>        */
>       void unlock();
>   }
>   ```
>
> * ###### 基于接口的简单分布式锁实现
>
>   ```java
>   package com.mofany.utils;
>   
>   import org.springframework.data.redis.core.StringRedisTemplate;
>   
>   import java.util.concurrent.TimeUnit;
>   
>   /**
>    * @author MoFany-J
>    * @date 2023/3/15
>    * @description SimpleRedisLock 简单的Redis锁
>    */
>   public class SimpleRedisLock implements ILock {
>       /**
>       * 锁的名称
>       */ 
>       private String name;
>       
>       /**
>       * StringRedisTemplate实例
>       */
>       private StringRedisTemplate stringRedisTemplate;
>   	
>       /**
>        * 锁对象构造器
>        * @param name 锁名
>        * @param stringRedisTemplate redis操作
>        * */
>       public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) {
>           this.name = name;
>           this.stringRedisTemplate = stringRedisTemplate;
>       }
>   	
>       /**
>   	* key前缀
>   	*/
>       private static final String KEY_PREFIX = "lock:";
>   
>       /**
>        * 尝试获取锁
>        *
>        * @param timeoutSec 锁持有的超时时间，过期自动释放
>        * @return true代表获取锁成功，false代表获取锁失败
>        */
>       @Override
>       public boolean tryLock(long timeoutSec) {
>           // 构建key
>           String key = KEY_PREFIX + name;
>           // 获取当前线程标识
>           long threadId = Thread.currentThread().getId();
>           // 构建value
>           String value = threadId + "";
>           // 获取锁
>           Boolean result = stringRedisTemplate
>               			.opsForValue().setIfAbsent(key, value, timeoutSec, TimeUnit.SECONDS);
>           // 防止自动拆箱时发生空指针异常
>           return Boolean.TRUE.equals(result);
>       }
>   
>       /**
>        * 锁释放
>        */
>       @Override
>       public void unlock() {
>           // 构建key
>           String key = KEY_PREFIX + name;
>           // 释放锁
>           stringRedisTemplate.delete(key);
>       }
>   }
>   ```
>
<<<<<<< HEAD
=======
>   * ##### 注意在极端情况下依然会发生线程并发安全问题：
>
>     * ###### 在业务阻塞严重时，会导致超时进行锁的释放，此时其它线程可能乘虚而入倒是其余阻塞结束的线程完成任务时造成锁的误删除操作。
>
>   #### 解决方案
>
>   * 给每一个线程加一个属于自己的唯一锁标识`UUID`
>   * 在每一次释放锁时进行判断，看当前要释放的锁的唯一标识是否与自己匹配

### :gem::gem:基于Redis的分布式锁实现`-改进版`

> #### 修改之前的分布式锁实现
>
> 1. 在获取锁时存入线程标识`UUID实现`
> 2. 在释放锁时先获取锁中的线程标识，判断是否与当前线程标识一致
>    * 如果一致则释放锁
>    * 如果不一致则不释放锁
>
> ```java
> package com.mofany.utils;
> 
> import cn.hutool.core.lang.UUID;
> import org.springframework.data.redis.core.StringRedisTemplate;
> 
> import java.util.concurrent.TimeUnit;
> 
> /**
>  * @author MoFany-J
>  * @date 2023/3/15
>  * @description SimpleRedisLock 简单的Redis锁
>  */
> public class SimpleRedisLock implements ILock {
>     private String name;
>     private StringRedisTemplate stringRedisTemplate;
> 
>     /**
>      * 锁对象构造器
>      *
>      * @param name                锁名
>      * @param stringRedisTemplate redis操作
>      */
>     public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) {
>         this.name = name;
>         this.stringRedisTemplate = stringRedisTemplate;
>     }
> 
>     private static final String KEY_PREFIX = "lock:";
>     
>     /**
>     * 加入UUID作为每一个线程的唯一锁标识
>     */
>     private static final String ID_PREFIX = UUID.randomUUID().toString(true) + "-";
> 
>     /**
>      * 尝试获取锁
>      *
>      * @param timeoutSec 锁持有的超时时间，过期自动释放
>      * @return true代表获取锁成功，false代表获取锁失败
>      */
>     @Override
>     public boolean tryLock(long timeoutSec) {
>         String key = KEY_PREFIX + name;
>         // 获取当前线程标识，即：value
>         String threadId = ID_PREFIX + Thread.currentThread().getId();
>         // 获取锁
>         Boolean result = stringRedisTemplate
>             			.opsForValue().setIfAbsent(key, threadId, timeoutSec, TimeUnit.SECONDS);
>         // 防止自动拆箱时发生空指针异常
>         return Boolean.TRUE.equals(result);
>     }
> 
>     /**
>      * 锁释放
>      */
>     @Override
>     public void unlock() {
>         // 要释放的锁
>         String lockKey = KEY_PREFIX + name;
>         // 获取当前线程标识
>         String threadId = ID_PREFIX + Thread.currentThread().getId();
>         // 读取当前锁中的标识
>         String lockId = stringRedisTemplate.opsForValue().get(lockKey);
> 
>         // 判断要释放的锁的id与当前线程持有的锁的id是否匹配
>         if (threadId.equals(lockId)) {
>             // 释放锁
>             stringRedisTemplate.delete(lockKey);
>         }
>     }
> }
> ```
>
> #### 由于判断锁标识与释放锁并非原子操作，故可能会发生阻塞极端情况：
>
> * 引起该阻塞是由于JVM中垃圾回收`FullGC`时而引起的全部代码阻塞问题
> * 若阻塞时间达到超时释放时间，则为超时释放，其它线程也可以乘虚而入，而当其余线程获取到锁时`FullGC`垃圾回收结束，原线程要释放锁，而此时另外的线程获取到了锁，则释放锁又会错误的释放别的锁`该错误释放锁时机发生在锁标识判断后锁释放前`

###  :gem::gem:基于Lua脚本的分布式锁实现`-加强版`

> #### 利用`Redis事务`保证断锁标识与释放锁并为一组原子操作`Lua`:ballot_box_with_check:
>
> * ###### `Lua脚本`调用`Redis命令`的函数
>
>   * ##### 本地必须要有Lua环境
>
>   * ###### Lua语言中数组下标从1开始
>
>   ```java
>   // Lua执行redis命令
>   redis.call('命令名称','key','其它参数',...)
>   ```
>
>   ```java
>   // 要执行的redis命令： set name Jack
>   redis.call('set','name','Jack')
>   ```
>
> * ##### `Redis命令`调用`Lua`脚本
>
>   * ###### 如果脚本中的key、value不想写死，则可以作为参数传递。key类型参数会放入keys数组，其它类型参数会放入ARGV数组，在脚本中可以从keys和argv数组获取这些参数！
>
>   ```sql
>   EVAL script numkeys key [key ...] arg [arg ...]
>   ```
>
>   * 如执行：`reids.call('set','name','Jack')`脚本函数对应的redis命令
>
>     ```sql
>     -- 调用Lua函数，无参调用
>     EVAL "return redis.call('set','name','Jack')" 0
>     
>     -- 调用Lua函数，有参调用
>     EVAL "return redis.call('set',KEYS[1],ARGV[1])" 1 name Jack
>     ```
>
>   * 无参测试
>
>     ```shell
>     > Windows-Docker-Redis connected!
>     
>     # 利用reids调用Lua脚本，参数0
>     > EVAL "return redis.call('set','name','Jack')" 0
>     OK
>     
>     # 查看所有key
>     > keys *
>     name
>     icr:order:2023:03:24
>     icr:order:2023:03:11
>     icr:order:2023:03:23
>     cache:shop:type:list
>     cache:shop:1
>     icr:order:2023:03:10
>     
>     # 获取指定key值
>     > get name
>     Jack
>     ```
>
>   * 有参测试：
>
>     ```shell
>     > Windows-Docker-Redis connected!
>     
>     # 利用reids调用Lua脚本，参数1
>     > EVAL "return redis.call('set',KEYS[1],ARGV[1])" 1 name Jack
>     OK
>     
>     # 查看所有key
>     > keys *
>     name
>     icr:order:2023:03:24
>     icr:order:2023:03:11
>     icr:order:2023:03:23
>     cache:shop:type:list
>     cache:shop:1
>     icr:order:2023:03:10
>     
>     # 获取指定key值
>     > get name
>     Jack
>     ```
>
>   #### 编写锁释放的Lua脚本:ballot_box_with_check:
>
>   1. 获取锁中的线程标识
>   2. 判断是否与指定的标识（当前线程标识）一致
>   3. 如果一致则释放锁（删除）
>   4. 如果不一致则什么都不做
>
>   ```lua
>   ---
>   --- Generated by EmmyLua(https://github.com/EmmyLua)
>   --- Created by jiang.
>   --- DateTime: 2023/3/24 8:58
>   --- 基于Lua脚本实现锁释放
>   ---
>   
>   -- 锁的key
>   local key = KEYS[1]
>   
>   -- 当前线程标识
>   local threadId = ARGV[1]
>   
>   -- 获取锁中的线程标识 get key
>   local id = redis.call('get', key)
>   
>   -- 判断线程标识与锁中的标识是否一致
>   if (id == threadId)
>   then
>       -- 一致则释放锁
>       redis.call('del', key)
>       return 1
>   else
>       -- 不一致则不做任何操作
>       return 0
>   end
>   ```
>
>   #### RedisTemplate调用Lua脚本的API
>
>   ```java
>   @Override
>   public <T> execute(RedisScript<T> script,list<k> keys,Object... args){
>   	return scriptExecutor.execute(script,keys,args);
>   }
>   ```
>
>   #### 最终版:ballot_box_with_check:
>
>   ```java
>   package com.mofany.utils;
>   
>   import cn.hutool.core.lang.UUID;
>   import org.springframework.core.io.ClassPathResource;
>   import org.springframework.data.redis.core.StringRedisTemplate;
>   import org.springframework.data.redis.core.script.DefaultRedisScript;
>   
>   import java.util.Collections;
>   import java.util.concurrent.TimeUnit;
>   
>   /**
>    * @author MoFany-J
>    * @date 2023/3/15
>    * @description SimpleRedisLock 简单的Redis锁
>    */
>   public class SimpleRedisLock implements ILock {
>       private String name;
>       private StringRedisTemplate stringRedisTemplate;
>   
>       /**
>        * 锁对象构造器
>        *
>        * @param name                锁名
>        * @param stringRedisTemplate redis操作
>        */
>       public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) {
>           this.name = name;
>           this.stringRedisTemplate = stringRedisTemplate;
>       }
>   
>       private static final String KEY_PREFIX = "lock:";
>   
>       /**
>        * 线程的唯一锁标识
>        */
>       private static final String ID_PREFIX = UUID.randomUUID().toString(true) + "-";
>   
>       /**
>        * 加载Lua脚本
>        */
>       private static final DefaultRedisScript<Long> UNLOCK_SCRIPT;
>   
>       static {
>           // 类首次加载时初始化
>           UNLOCK_SCRIPT = new DefaultRedisScript<>();
>           // 指定脚本位置
>           UNLOCK_SCRIPT.setLocation(new ClassPathResource("script/unlock.lua"));
>           // 指定返回值类型
>           UNLOCK_SCRIPT.setResultType(Long.class);
>       }
>   
>       /**
>        * 尝试获取锁
>        *
>        * @param timeoutSec 锁持有的超时时间，过期自动释放
>        * @return true代表获取锁成功，false代表获取锁失败
>        */
>       @Override
>       public boolean tryLock(long timeoutSec) {
>           String key = KEY_PREFIX + name;
>           // 获取当前线程标识，即：value
>           String threadId = ID_PREFIX + Thread.currentThread().getId();
>           // 获取锁
>           Boolean result = stringRedisTemplate
>               .opsForValue().setIfAbsent(key, threadId, timeoutSec, TimeUnit.SECONDS);
>           // 防止自动拆箱时发生空指针异常
>           return Boolean.TRUE.equals(result);
>       }
>   
>       /**
>        * 锁释放
>        */
>       @Override
>       public void unlock() {
>           String key = KEY_PREFIX + name;
>           // 获取当前线程标识，即：value
>           String value = ID_PREFIX + Thread.currentThread().getId();
>           // 调用Lua脚本进行锁释放
>           stringRedisTemplate.execute(UNLOCK_SCRIPT, Collections.singletonList(key), value);
>       }
>   }
>   ```
>
>>>>>>> origin
>
>
>
>

## Redis集群

>
>
>

## Redis主从复制

>

## Redis哨兵机制

>
>
>

## Redis实现分布式Session管理

>
>
>

# Redis原理

## Redis数据持久化方式详解

>#### DB
>
>```properties
>################################ SNAPSHOTTING  ################################
>
># Save the DB to disk.
>#
># save <seconds> <changes>
>#
># Redis will save the DB if both the given number of seconds and the given
># number of write operations against the DB occurred.
>#
># Snapshotting can be completely disabled with a single empty string argument
># as in following example:
>#
># save ""
>#
># Unless specified otherwise, by default Redis will save the DB:
>#   * After 3600 seconds (an hour) if at least 1 key changed
>#   * After 300 seconds (5 minutes) if at least 100 keys changed
>#   * After 60 seconds if at least 10000 keys changed
>#
># You can set these explicitly by uncommenting the three following lines.
>#
># save 3600 1
># save 300 100
># save 60 10000
>
># By default Redis will stop accepting writes if RDB snapshots are enabled
># (at least one save point) and the latest background save failed.
># This will make the user aware (in a hard way) that data is not persisting
># on disk properly, otherwise chances are that no one will notice and some
># disaster will happen.
>#
># If the background saving process will start working again Redis will
># automatically allow writes again.
>#
># However if you have setup your proper monitoring of the Redis server
># and persistence, you may want to disable this feature so that Redis will
># continue to work as usual even if there are problems with disk,
># permissions, and so forth.
>```
>
>#### AOF
>
>```java
>
>```
>
>